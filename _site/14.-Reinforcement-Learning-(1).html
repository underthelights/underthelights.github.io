<!DOCTYPE html>
<html lang="en"><head>
  
  <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
         TeX: {
         equationNumbers: {
             autoNumber: "AMS"
         }
         },
         tex2jax: {
         inlineMath: [ ['$', '$'] ],
         displayMath: [ ['$$', '$$'] ],
         processEscapes: true,
     }
     });
     MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
         alert("Math Processing Error: "+message[1]);
         });
     MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
         alert("Math Processing Error: "+message[1]);
         });
     </script>
<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
  

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <title>14. Reinforcement Learning (1) âœ± Kyuhwan Shim</title>

  <link rel="stylesheet" href="/assets/css/style.css">

  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Barlow:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800&family=Noto+Sans+TC&display=swap" rel="stylesheet">

  <link href="/assets/fontawesome/all.min.css" rel="stylesheet">

  <!-- Bootstrap -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Zenh87qX5JnK2Jl0vWa8Ck2rdkQ2Bzep5IDxbcnCeuOxjzrPF/et3URy9Bv1WTRi" crossorigin="anonymous">
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-OERcA2EqjJCMA+/3y+gxIOqMEjwtxJY7qPCqsdltbNJuaOe923+mo//f6V8Qbsw3" crossorigin="anonymous"></script>
  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js'></script>

  <!-- GA -->
  
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VG8LB4J4EL"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VG8LB4J4EL');
</script>


  <!-- favicon -->
  <link rel="apple-touch-icon" sizes="57x57" href="/assets/images/main/favicon/favicon.ico">
  <link rel="apple-touch-icon" sizes="57x57" href="/assets/images/main/favicon/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/assets/images/main/favicon/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/assets/images/main/favicon/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/assets/images/main/favicon/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/assets/images/main/favicon/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/assets/images/main/favicon/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/assets/images/main/favicon/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/assets/images/main/favicon/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/images/main/favicon/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="/assets/images/main/favicon/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/images/main/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/assets/images/main/favicon/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/images/main/favicon/favicon-16x16.png">
  <link rel="manifest" href="">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/assets/images/main/favicon/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">

  <!-- Opengraph -->
  <meta property="og:type" content="website">
  <meta property="og:image" content="/assets/images/main/favicon/og.png14.-Reinforcement-Learning-(1).jpg">
  <meta property="og:title" content="14. Reinforcement Learning (1) | Kyuhwan Shim">
  <meta property="og:description" content="Paper overview of  et al., ">

  <!-- Google scholar -->
  
  <meta name="citation_title" content="14. Reinforcement Learning (1)">
  
  <meta name="citation_publication_date" content="">
  
  <meta name="citation_conference_title" content="">
  
  <meta name="citation_pdf_url" content="https://underthelights.github.io/assets/pdf/14.-Reinforcement-Learning-(1).pdf">
  
</head>
<body><header class="page-content">
  <nav class="navbar navbar-expand-md navbar-light py-4">
    <div class="container-fluid">
      <button class="navbar-toggler ms-auto" type="button" data-bs-toggle="collapse" data-bs-target="#navbarTogglerDemo01" aria-controls="navbarTogglerDemo01" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarTogglerDemo01">
        <ul class="navbar-nav ms-auto mt-4 mt-lg-0 navbar-nav-scroll">
          <li class="nav-item">
            <a class="nav-link " aria-current="page" href="/">Home</a>
          </li>
          <li class="nav-item">
            <a class="nav-link " aria-current="page" href="/news">News</a>
          </li>
          <li class="nav-item">
            <a class="nav-link " aria-current="page" href="/publication">publication</a>
          </li>
          <li class="nav-item">
            <a class="nav-link " aria-current="page" href="/project">Project</a>
          </li>
          <li class="nav-item">
            <a class="nav-link " aria-current="page" href="/oconnect">oconnect</a>
          </li>
          <li class="nav-item">
            <a class="nav-link " aria-current="page" href="/cv">CV</a>
          </li>
          <li class="nav-item dropdown">
              <a href="#" class="nav-link dropdown-toggle " data-bs-toggle="dropdown">fun</a>
              <div class="dropdown-menu">
                  <a href="/music" class="dropdown-item">music</a>
                  <a href="/artwork" class="dropdown-item">artwork</a>
              </div>
          </li>
          <li class="nav-item">
            <a class="nav-link " aria-current="page" target="_blank" rel="noopener noreferrer" href="https://underthelights.github.io/blog/">Blog<i class="fa-regular fa-arrow-up-right-from-square" style="padding-left: 5px;"></i></a>
          </li>
        </ul>
      </div>
    </div>
  </nav>
</header>

<style>
  .dropdown-toggle {
    background-color: transparent;
    border-color: #fff;
    border-style: solid;
    border-top: none;
    border-right: none;
    border-left: none;
    transition: color .15s ease-in-out, background-color .15s ease-in-out,border-color .15s ease-in-out;
  }
  .dropdown-toggle:hover {
    font-weight: 500
  }
  .dropdown:hover .dropdown-menu {
    display: block;
    margin-top: 0;
 }
 .dropdown-menu {
    --bs-dropdown-border-radius: 0 !important;
    padding-top: 0 !important;
    padding-bottom: 0 !important
 }
 .dropdown-item {
  font-size: .95rem !important;
  padding: .3rem .75rem !important;
 }
 .dropdown-item:active {
  background-color: #999 !important
 }
</style><main class="page-content" aria-label="Content">
      <div class="wrapper">
        <style>
  h1,
  h2,
  h3,
  h4,
  h5,
  h6 {
    
      font-family: 'Arial', sans-serif;
      /* Use a modern font */
      margin-top: 20px;
      margin-bottom: 10px;
  }
  /* í¬ìŠ¤íŠ¸ í—¤ë”ì— ì ìš©ë˜ëŠ” ì—¬ë°± ì œê±° */
  .post-header, h1, h2, h3, h4, h5, h6 {
      margin-left: 0 !important; 
      padding-left: 0 !important;
  }


  .post-title {
      font-size: 2em; /* í°íŠ¸ í¬ê¸° ì¦ê°€ */
      font-weight: bold; /* ë³¼ë“œì²´ */
      color: #333; /* ìƒ‰ìƒ ë³€ê²½ */
      box-shadow: inset 0 -20px 0 #bbb7e8;
      max-width: max-content;
    }

  /* Updated styling for h1 */
  h1 {
    font-size: 1.5em;
    /* Increase font size for main titles */
    box-shadow: inset 0 -10px 0 #bbb7e8;
    max-width: max-content; 
    font-weight: bold; /* ë³¼ë“œì²´ */
    border-bottom: none;
    /* Remove bottom border */
    padding-bottom: 0;
    /* Adjust padding if needed */
  }

  h2 {
    font-size: 1.2em;
    margin-left: none;
    font-weight: bold; /* ë³¼ë“œì²´ */
    max-width: max-content; 
    background-color: #cdcbe9;
  }

  h3 {
    font-size: 1.1em;
    max-width: max-content; 
    
    max-width: max-content; 
    background-color: #bbb7e8;
  }

  h4 {
    font-size: 0.75em;
    color: #888888;
  }

  h5 {
    font-size: 0.5em;
    color: #a6a6a6;
  }

  h6 {
    font-size: 1em;
    color: #bcbcbc;
  }

  /* Add some additional styling if needed */
  .post-content {
    margin-left: 20px; /* ì™¼ìª½ ì—¬ë°± ì¶”ê°€ */
    /* margin-right: 20px; ì˜¤ë¥¸ìª½ì— TOC ë„ˆë¹„ + ì—¬ë°± ë§Œí¼ ì¶”ê°€ */
    line-height: 1.6;/* Improve readability */
    color: #333;/* Dark grey color for text */
  }
  /* Category Chart Style */
  .category-chart {
    font-family: 'Arial', sans-serif;
    /* width: 100%; */
    /* height: 100px; Adjust as needed */
  }

  .category-list li {
    display: inline-block;
    margin-right: 20px;
  }
  /* ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼ */
  img {
    display: block; /* ì´ë¯¸ì§€ë¥¼ ë¸”ë¡ ë ˆë²¨ë¡œ ì„¤ì • */
    width: 50%; /* ë˜ëŠ” ì›í•˜ëŠ” ë„ˆë¹„ */
    height: auto; /* ë¹„ìœ¨ ìœ ì§€ */
    margin-bottom: 5px; /* ì´ë¯¸ì§€ì™€ ìº¡ì…˜ ì‚¬ì´ì˜ ê°„ê²© */
    text-align: center;
  }

  /* ì´ë¯¸ì§€ ìº¡ì…˜ ìŠ¤íƒ€ì¼ë§ */
  .em {
    color: #757575;
    font-size: 0.8em;
    
    /* margin-top: 5px; */
    display: block; /* ìº¡ì…˜ì„ ë¸”ë¡ ìš”ì†Œë¡œ ì„¤ì •, ì´ë¯¸ì§€ ì•„ë˜ë¡œ ê°•ì œ ë°°ì¹˜ */
    text-align: center;
    margin-bottom: 5px;
  }
  /* Blockquote ìŠ¤íƒ€ì¼ */
  blockquote {
      margin-left: 20px;
      border-left: 1.5px solid #ccc; /* ì¢Œì¸¡ ì„  */
      border-top: 1.5px solid #ccc; /* ì¢Œì¸¡ ì„  */
      border-right: 1.5px solid #ccc; /* ì¢Œì¸¡ ì„  */
      border-bottom: 1.5px solid #ccc; /* ì¢Œì¸¡ ì„  */

      padding-left: 15px;
      color: #666; /* ê¸€ì ìƒ‰ìƒ */
  }



</style>

<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <!-- Table of Contents Container -->
<div class="toc-container">
    <nav class="toc">
      <strong>Table of Contents</strong>
      <!--  -->
      <!-- Jekyll TOC Liquid Code -->
      <ul><li><a href="#characteristics-of-reinforcement-learning">Characteristics of Reinforcement Learning</a><ul><li><a href="#examples-of-reinforcement-learning">Examples of Reinforcement Learning</a></li></ul></li><li><a href="#rewards">Rewards</a><ul><li><a href="#examples-of-rewards">Examples of Rewards</a></li></ul></li><li><a href="#sequential-decision-making">Sequential Decision Making</a></li><li><a href="#agent-and-environment">Agent and Environment</a></li><li><a href="#major-components-of-an-rl-agent">Major Components of an RL Agent</a><ul><li><a href="#example---maze">Example - Maze</a></li></ul></li><li><a href="#bellman-equation">Bellman equation</a></li></ul>

      <!-- <ul><li><a href="#characteristics-of-reinforcement-learning">Characteristics of Reinforcement Learning</a><ul><li><a href="#examples-of-reinforcement-learning">Examples of Reinforcement Learning</a></li></ul></li><li><a href="#rewards">Rewards</a><ul><li><a href="#examples-of-rewards">Examples of Rewards</a></li></ul></li><li><a href="#sequential-decision-making">Sequential Decision Making</a></li><li><a href="#agent-and-environment">Agent and Environment</a></li><li><a href="#major-components-of-an-rl-agent">Major Components of an RL Agent</a><ul><li><a href="#example---maze">Example - Maze</a></li></ul></li><li><a href="#bellman-equation">Bellman equation</a></li></ul> -->
    </nav>
</div>

<style>
    /* TOC ìŠ¤íƒ€ì¼ */
.toc-container {
  position: fixed;
  right: 10px;
  top: 100px;
  z-index: 1000;
  /* max-width: 50px; ê°€ë¡œ ë„ˆë¹„ ì¡°ì •, í•„ìš”ì— ë”°ë¼ ê°’ì„ ë³€ê²½í•˜ì„¸ìš” */
  font-size: 0.75rem;
}

.toc {
  border: 1px solid #ddd;
  padding: 10px;
  border-radius: 5px;
  background-color: white;
  box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
  max-width: 200px; /* ê°€ë¡œ ë„ˆë¹„ ì¡°ì •, í•„ìš”ì— ë”°ë¼ ê°’ì„ ë³€ê²½í•˜ì„¸ìš” */
}


.toc strong {
  display: block;
  margin-bottom: 10px;
}

.toc ul {
  list-style: none;
  padding: 0;
  margin: 0;
}

.toc ul li a {
  text-decoration: none;
  color: #007bff;
  display: block;
  padding: 5px 0;
}

.toc ul li a:hover,
.toc ul li a.active { /* ì¶”ê°€ëœ active í´ë˜ìŠ¤ ìŠ¤íƒ€ì¼ */
  font-weight: bold;
  /* box-shadow: inset 0 -10px 0 #bbb7e8; */
  background-color: #bbb7e8;
}



  button {
    padding: 5px 10px;
    /* ìƒí•˜ 10px, ì¢Œìš° 20px íŒ¨ë”©ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì£¼ë³€ ì—¬ìœ  ê³µê°„ ì¶”ê°€ */
    font-size: 0.87rem;
    /* ê¸€ì í¬ê¸° */
    color: white;
    /* ê¸€ì ìƒ‰ìƒ */
    background-color: #007bff;
    /* ë°°ê²½ ìƒ‰ìƒ */
    border: none;
    /* í…Œë‘ë¦¬ ì œê±° */
    border-radius: 5px;
    /* ëª¨ì„œë¦¬ ë‘¥ê¸€ê²Œ */
    cursor: pointer;
    /* ì»¤ì„œ ëª¨ì–‘ ë³€ê²½ */
    transition: background-color 0.3s;
    /* í˜¸ë²„ íš¨ê³¼ë¥¼ ìœ„í•œ ì „í™˜ ì„¤ì • */
    text-align: center;
    /* ê¸€ìë¥¼ ë²„íŠ¼ ì¤‘ì•™ì— ìœ„ì¹˜ */
    display: inline-block;
    /* ì¸ë¼ì¸ ë¸”ë¡ ìš”ì†Œë¡œ ì„¤ì •í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ í…ìŠ¤íŠ¸ ì¤‘ì•™ ì •ë ¬ */
    line-height: normal;
    /* ê¸°ë³¸ ë¼ì¸ ë†’ì´ ì„¤ì • */
    vertical-align: middle;
    /* ìˆ˜ì§ ë°©í–¥ìœ¼ë¡œ ì¤‘ì•™ ì •ë ¬ */
    margin-top: 5px;
  }

  button:hover {
    background-color: #0056b3;
    /* í˜¸ë²„ ì‹œ ë°°ê²½ ìƒ‰ìƒ ë³€ê²½ */
  }


  /* reset base styles */
  * {
    box-sizing: border-box;
    margin: 0;
    padding: 0;
  }

  /* page header */
  header {
    margin-bottom: 2rem;
    padding-left: 6.5rem;
  }

  header h1 {
    font-size: 1.5rem;
  }

  header p {
    margin: .5rem 0;
    font-size: 1rem !important
  }

  main b {
    font-weight: 500
  }

  /* normal body content */
  h2 {
    font-size: 1.1rem;
    margin-bottom: 0.75rem;
    margin-left: 6.5rem;
    text-transform: uppercase;
  }

  h3 {
    border-bottom: 1px solid black;
    font-size: .9rem;
    margin: 1rem 0 .5rem 6.5rem
  }

  p {
    margin-bottom: 0.5rem;
  }

  a {
    color: inherit;
    /*#0000ee;*/
  }

  section {
    margin-bottom: 3rem;
  }

  /* misc */
  .pdf {
    font-size: .9rem !important;
    font-weight: 300;
    margin-left: 1.5rem;
    white-space: nowrap;
  }

  .pdf i {
    margin-right: .1rem;
  }

  .material {
    font-size: small;
    margin-left: .5rem;
  }

  :global(i) {
    padding-right: 4px !important
  }

  /* dated entries */
  .dated-entry {
    display: flex;
    flex-flow: row wrap;
    position: relative;
    margin-bottom: 1rem;
  }

  .dated-date {
    width: 6.5rem;
    text-align: right;
    padding-top: .15rem;
    padding-right: 1.5rem;
    font-size: .8rem
  }

  .dated-content {
    width: calc(100% - 6.5rem);
    font-size: .95rem
  }

  .oneline-entries {
    margin-bottom: 0.5rem;
  }

  .oneline-entries .dated-entry {
    margin-bottom: 0;
  }

  /* hide extra awards info for now, not sure what to include */
  #awards em {
    display: none;
  }

  .author-tooltip {
    font-weight: 400;
    font-size: .8rem !important;
    text-align: center;
  }

  /* on narrow displays, make the font smaller */
  @media (max-width: 480px) {
    html {
      font-size: 14px;
    }
  }

  /* when printing, make the font smaller and the page full-width */
  @media print {
    html {
      font-size: 12px;
    }

    main {
      margin-top: 0;
      max-width: 100%;
    }
  }

</style>

<script>
    document.addEventListener('scroll', function() {
      var sections = document.querySelectorAll('section'); // ì„¹ì…˜ ì„ íƒì ìˆ˜ì •
      var menu_links = document.querySelectorAll('.toc a'); // TOC ë§í¬ ì„ íƒì ìˆ˜ì •
    
      var fromTop = window.scrollY;
    
      sections.forEach(function(section) {
        if (section.offsetTop <= fromTop && section.offsetTop + section.offsetHeight > fromTop) {
          menu_links.forEach(function(link) {
            if (section.getAttribute('id') && link.getAttribute('href').includes(section.getAttribute('id'))) {
              link.classList.add('active');  // í˜„ì¬ ì„¹ì…˜ì˜ TOC ë§í¬ì— 'active' í´ë˜ìŠ¤ ì¶”ê°€
            } else {
              link.classList.remove('active'); // ë‹¤ë¥¸ ëª¨ë“  ë§í¬ì—ì„œ 'active' í´ë˜ìŠ¤ ì œê±°
            }
          });
        }
      });
    });
    </script>
    

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">14. Reinforcement Learning (1)</h1>
    <p class="post-meta"><time class="dt-published" datetime="2022-06-12T00:00:00+02:00" itemprop="datePublished">
        Jun 12, 2022
      </time></p>
    <!-- íƒœê·¸ì™€ ì¹´í…Œê³ ë¦¬ í‘œì‹œ -->
    <div class="post-categories">
      
      <strong><span>ğŸ“š Categories:</span></strong>
      
      <a href="blog-categories-notes">Notes</a>
      
      
    </div>

    <div class="post-tags">
      
      <strong><span>ğŸ·ï¸ Tags:</span></strong>
      
      <a href="blog-tags-ml">ML</a>
      
      
    </div>


  </header>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h1 id="characteristics-of-reinforcement-learning">Characteristics of Reinforcement Learning</h1>

<p><img src="/assets/img/2022-06-12-14.-Reinforcement-Learning-(1).md/0.png" alt="0" /></p>

<ul>
  <li>What makes reinforcement learning different from other machine learning paradigms?
    <ul>
      <li>supervised l. vs unsupervised l. vs. RL
        <ul>
          <li>supervised : label + data</li>
          <li>Unsupervised : just use given data</li>
          <li>RL : data + reward - Rewardì— í•´ë‹¹í•˜ëŠ” ì¶”ê°€ì ì¸ inputì´ ì¡´ì¬í•¨</li>
        </ul>
      </li>
    </ul>

    <p>â†’ There is no supervisor, only a reward signal</p>
  </li>
  <li>Feedback is delayed, not instantaneous</li>
  <li>Time really matters (sequential, non i.i.d. data)
    <ul>
      <li>ì‹œê°„ì´ ì¤‘ìš”í•œ ìš”ì†Œ ì¤‘ í•˜ë‚˜</li>
      <li>sequential : ì „ë°˜ì˜ ì„ íƒì´ í›„ë°˜ì˜ ì„ íƒì— ì˜í–¥
  iid = independent identically distributed - ìƒí˜¸ ì—°ê´€</li>
    </ul>
  </li>
  <li>Agentâ€™s actions affect the subsequent data it receives
    <ul>
      <li>agent actionì´ ì´í›„ dataì— ì˜í–¥ì„ ë¯¸ì¹œë‹¤.</li>
    </ul>
  </li>
</ul>

<h2 id="examples-of-reinforcement-learning">Examples of Reinforcement Learning</h2>

<ul>
  <li>Fly stunt manoeuvres in a helicopter
    <ul>
      <li>í—¬ë¦¬ì½¥í„°ì˜ ë¹„í–‰ ëª¨í˜•</li>
    </ul>
  </li>
  <li>Defeat the world champion at Backgammon
    <ul>
      <li>backgammon ê²Œì„ì—ì„œì˜ ì‘ìš©</li>
    </ul>
  </li>
  <li>Manageaninvestmentportfolio</li>
  <li>Controlapowerstation</li>
  <li>Makeahumanoidrobotwalk</li>
  <li>Play many different Atari games better than humans
    <ul>
      <li>ë¡œë´‡, íˆ¬ì í¬íŠ¸í´ë¦¬ì˜¤, ì•„íƒ€ë¦¬ ê²Œì„ì—ì„œì˜ í•™ìŠµ</li>
    </ul>

    <p><img src="/assets/img/2022-06-12-14.-Reinforcement-Learning-(1).md/1.png" alt="1" /></p>

    <p><img src="/assets/img/2022-06-12-14.-Reinforcement-Learning-(1).md/2.png" alt="2" /></p>
  </li>
</ul>

<h1 id="rewards">Rewards</h1>

<ul>
  <li>A reward ğ’• is a scalar feedback signal</li>
  <li>Indicate show well agent is doing at step t &amp; The agentâ€™s job is to maximize cumulative reward</li>
  <li>ê°ê°ì˜ ì‹œê°„ì— ì–¼ë§ˆë‚˜ ì˜ í–‰ë™ í–ˆëŠ”ì§€ ë³´ê³  reward ìµœëŒ€í™”ë˜ëŠ” ë°©í–¥ìœ¼ë¡œ í–‰ë™í•˜ë„ë¡ í•™ìŠµ</li>
  <li>Reinforcementlearning is based on the reward hypothesis
    <ul>
      <li>reward = ì‚¬ëŒì´ ë§Œë“  ê¸°ì¤€
  ex. Atari game : target ë³„ ìµœëŒ€í•œì˜ ì ìˆ˜ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•™ìŠµì´ ë˜ê¸°ë„ í•¨. ì ìˆ˜ê°€ ë§ì€ ìª½ì„ ë” ë¹¨ë¦¬ ì–»ì„ ìˆ˜ ìˆë„ë¡ í•™ìŠµì‹œí‚¤ëŠ” ì–‘ìƒì´ ìƒê¸¸ ìˆ˜ ìˆë‹¤,</li>
      <li>Reward hypothesis: all goals can be described by the m<strong>aximization of expected cumulative reward</strong></li>
    </ul>
  </li>
</ul>

<h2 id="examples-of-rewards">Examples of Rewards</h2>

<ul>
  <li>
    <p>Fly stunt manoeuvres in a helicopter</p>

    <p>(+) : ì›í•˜ëŠ” ê¶¤ì ì„ ê·¸ë¦¬ë©° ë‚ ì•„ê°ˆ ë•Œ
  (-) : crashing ì‹œ ë§ˆì´ë„ˆìŠ¤ ã…ê³¼</p>

    <ul>
      <li>+ve reward for following desired trajectory</li>
      <li>âˆ’ve reward for crashing</li>
    </ul>
  </li>
  <li>Defeat the world champion at Backgammon
    <ul>
      <li>+/âˆ’ve reward for winning/losing a game</li>
    </ul>
  </li>
  <li>
    <p>Manage an investment portfolio</p>

    <p>(+) : ì›í•˜ëŠ” ì´ìµ
  (-) : ì†ì‹¤</p>

    <ul>
      <li>+ve reward for each $ in bank</li>
    </ul>
  </li>
  <li>
    <p>Control a power station</p>

    <p>(+) : ì ì ˆí•œ ì „ë ¥ ê³µê¸‰
  (-) :</p>

    <ul>
      <li>+ve reward for producing power</li>
      <li>âˆ’ve reward for exceeding safety thresholds</li>
    </ul>
  </li>
  <li>
    <p>Make a humanoid robot walk</p>

    <p>(+) : ì£¼ì–´ì§„ í™˜ê²½ì—ì„œ target ë¬¼ì§ˆì„ í™•ë³´ì—ì„œ mission ì˜ ìˆ˜í–‰
  (-) : ë„˜ì–´ì§</p>

    <ul>
      <li>+ve reward for forward motion</li>
      <li>âˆ’ve reward for falling over</li>
    </ul>
  </li>
  <li>
    <p>Play many different Atari games better than humans</p>

    <p>(+) : ì ìˆ˜ ì–»ê±°ë‚˜
  (-) : ì ìˆ˜ ìƒê±°ë‚˜
  -&gt; ë¹ ë¥¸ ì‹œê°„ ì•ˆì— ì ìˆ˜ë¥¼ ë§ì´ ì–»ëŠ” ë°©í–¥ìœ¼ë¡œ</p>

    <ul>
      <li>+/âˆ’ve reward for increasing/decreasing score</li>
    </ul>
  </li>
</ul>

<h1 id="sequential-decision-making">Sequential Decision Making</h1>

<ul>
  <li>í˜„ì¬ì˜ actionì´ ë‹¤ìŒ í„´ actionì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ë°, ì˜¤ëœ turnì— ëŒ€í•´ ì˜í–¥ì„ ë¼ì¹ ìˆ˜ë„ ìˆìŒ.</li>
  <li>Goal: select actions to maximize total future reward
    <ul>
      <li>ì¼ë ¨ì˜ í–‰ë™ì— ë”°ë¥¸ rewardê°€ ìµœëŒ€ê°€ ë˜ë„ë¡ í•™ìŠµí•œë‹¤</li>
    </ul>
  </li>
  <li>Actions may have long term consequences
    <ul>
      <li>stateê°€ ìˆê³  actionì„ ì·¨í•´ì„œ s1-(a1)-&gt;s2-(a2)-&gt;s3</li>
    </ul>
  </li>
  <li>Reward may be delayed rewardëŠ” delayë¥¼ ìˆ˜ë°˜í•˜ì—¬ ì£¼ì–´ì§ˆ ìˆ˜ ìˆë‹¤</li>
  <li>í˜„ì¬ actionìœ¼ë¡œ ì¸í•œ rewardì— ë” ì¤‘ì ì„ ë‘˜ ê²ƒì¸ì§€, ë¯¸ë˜ì˜ rewardì— ì¤‘ì ì„ ë” ë‘˜ ê²ƒì¸ì§€ : user settingí•  ìˆ˜ë„ ìˆê³  í•™ìŠµ ë‹¨ê³„ì—ì„œ ì–´ë–»ê²Œ parameterë¥¼ ì„¤ì •í–ˆëŠ”ì§€ì— ë”°ë¼ / í•™ìŠµì´ ì˜ íš¨ê³¼ì ìœ¼ë¡œ ì´ë£¨ì–´ì§ˆìˆ˜ ìˆëŠ”ì§€ë¥¼ ê³ ë ¤í•˜ì—¬ ëª¨ìˆ˜ ì¡°ì •
    <ul>
      <li>(greedy) í˜„ì¬ rewardì— ì´ˆì ì„ ë§ì¶”ëŠ” ê²½ìš° - current reward</li>
      <li>(optimal) ì „ì²´ rewardì— ì´ˆì ì„ ë§ì¶”ëŠ” ê²½ìš° - total reward
        <ul>
          <li>Itmay be better to sacrifice immediate reward to gain more long-term reward (greedy optimal)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Examples:</p>

    <p>Ex.
  -íˆ¬ì :ë‹¹ì¥ì€ ì†í•´ê°€ ë‚˜ë”ë¼ë„ ë¯¸ë˜ ì‹œì ì— ìˆ˜ìµ
  -í—¬ë¦¬ì½¥í„° ì£¼í–‰ ì¤‘ ì—°ë£Œ ì£¼ì… : crashí•˜ë©´ negative penaltyí•˜ê¸°ì— í˜„ì¬ë¡œì„œëŠ” reward ì¤„ì§€ë§Œ optimalí•˜ê²ŒëŠ” ëŠ˜ì–´ë‚˜ëŠ” reward
  -ì²´ìŠ¤ì—ì„œ ìƒëŒ€ë°© ì´ë™ : ë³¸ì¸ ì ìˆ˜ ì·¨í•˜ëŠ” ê²ƒë³´ë‹¤ ìƒëŒ€ë°© ë°©í•´ê°€ ì „ì²´ì ìœ¼ë¡œ ë” ì´ë“ì¼ìˆ˜ë„ ìˆëŠ” ê²½ìš°</p>

    <ul>
      <li>A financial investment (may take months to be mature)</li>
      <li>Refueling a helicopter (might prevent a crash in several hours)</li>
      <li>Blocking opponent moves (might help winning chances many moves from now)</li>
    </ul>
  </li>
</ul>

<h1 id="agent-and-environment">Agent and Environment</h1>

<p><img src="/assets/img/2022-06-12-14.-Reinforcement-Learning-(1).md/3.png" alt="3" /></p>

<ul>
  <li>At each stept the agent: agentê°€ ì£¼ë³€ì„ ê´€ì°°í•˜ê³ , rewardë¥¼ ë°›ì•„ actionì„ ì·¨í•¨
    <ul>
      <li>Executes action At</li>
      <li>Receives observation Ot</li>
      <li>Receives scalar reward Rt</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/2022-06-12-14.-Reinforcement-Learning-(1).md/4.png" alt="4" /></p>

<ul>
  <li>The environment:
    <ul>
      <li>Receives action At</li>
      <li>Emits observation Ot+1</li>
      <li>Emits scalar reward Rt+1</li>
    </ul>
  </li>
  <li>t increments at env. step</li>
</ul>

<p>&lt;agent, environmentì˜ ìƒí˜¸ì‘ìš©&gt;
agentëŠ” actionì„ ì·¨í•˜ê³  stateì— ë”°ë¼ Rewardë¥¼ ë°›ê²Œ ë¨
envëŠ” actionì„ ë°›ì•„ë“¤ì—¬ì„œ agentì—ê²Œ ì£¼ê³  ë³€í™˜ëœ statementë¥¼ agentì—ê²Œ ì¤Œ</p>

<ul>
  <li>tíƒ€ì„ìœ¼ë¡œ ì´ë£¨ì–´ì§€ëŠ” ìš”ì†Œë“¤</li>
</ul>

<p>actionì— ëŒ€í•´ì„œ rewardì™€ statementì˜ ë³€í™”</p>

<p><img src="/assets/img/2022-06-12-14.-Reinforcement-Learning-(1).md/5.png" alt="5" /></p>

<h1 id="major-components-of-an-rl-agent">Major Components of an RL Agent</h1>

<ul>
  <li>An RL agent may include one or more of these components:
    <ul>
      <li>Policy: agentâ€™s behavior function í–‰ë™ ì •ì˜</li>
      <li>Value function: how good is each state and/or action ì–¼ë§ˆë‚˜ ì¢‹ì€ê°€</li>
      <li>Model: agentâ€™s representation of the environment  í•™ìŠµ ëª¨ë¸</li>
    </ul>
  </li>
</ul>

<h2 id="example---maze">Example - Maze</h2>

<p><img src="/assets/img/2022-06-12-14.-Reinforcement-Learning-(1).md/6.png" alt="6" /></p>

<ul>
  <li>Agent: explores environment and gets reward</li>
  <li>Environment: agent ëŒì•„ë‹¤ë‹ˆëŠ” í™˜ê²½ situation being explored by the agent</li>
  <li>States: ìœ„ì¹˜ - positions/locations in the environment</li>
  <li>Actions: ìƒí•˜ì¢Œìš° - allowed movements for the agent</li>
  <li>Reward: what agent gets as it moves</li>
</ul>

<p><img src="/assets/img/2022-06-12-14.-Reinforcement-Learning-(1).md/7.png" alt="7" /></p>

<ul>
  <li>
    <p>For example, bomb has reward -10, germ has reward 10, every other move has rewards -1</p>

    <p>â†’ ë¶ˆí•„ìš”í•œ ì´ë™ì„ ìµœì†Œí™”ì‹œí‚¤ê¸° ìœ„í•œ ì¥ì¹˜</p>
  </li>
</ul>

<p>s6 is blocked</p>

<p><img src="/assets/img/2022-06-12-14.-Reinforcement-Learning-(1).md/8.png" alt="8" /></p>

<p><img src="/assets/img/2022-06-12-14.-Reinforcement-Learning-(1).md/9.png" alt="9" /></p>

<h1 id="bellman-equation">Bellman equation</h1>

\[V(s) = max_a(R(s,a) + \gamma V(s'))\]

<ul>
  <li>$R(s,a)Â $: reward: stateì—ì„œ ì·¨í•œ actionì— ë”°ë¥¸ reward</li>
  <li>$V(s)$ : is the value function - value function:ì „ì²´ reward ë¥¼ ì–´ë–»ê²Œ í‘œí˜„í•  ê²ƒì¸ê°€</li>
  <li>$\gamma$ : is the discounting factor
    <ul>
      <li>í˜„ì¬-ë¯¸ë˜ rewardì¤‘ ì–´ëŠ ê²ƒì— ì´ˆì ì„ ë§ì¶œ ê²ƒì¸ì§€ ì¤‘ìš”ë„ ë§ì¶”ëŠ” ìƒìˆ˜</li>
    </ul>
  </li>
  <li>$sâ€™$ : is the next state agent can go from
    <ul>
      <li>s : í˜„ì¬ state, sâ€™ : next state</li>
    </ul>
  </li>
  <li>Bellman equation is used to calculate the value function 
â†’ ê° stateì— ëŒ€í•œ value functionê°’ìœ¼ë¡œ ì£¼ì–´ì§€ê²Œ ë¨ : í™˜ê²½ì´ ë°”ë€Œë©´ ê²°ê³¼ê°€ ë°”ë€Œê²Œ ë¨
R(s,a) : current reward
V(sâ€™) : all futer reward</li>
  <li>ì¼ë°˜ì ì¸ ê·œì¹™:í­íƒ„,ë³´ì„ì´ ìˆê³  envê°€ ë‹¬ë ¤ì ”ì„ ë•Œ í•™ìŠµì„ ë” ì˜ í• ê²ƒì¸ê°€-&gt;bellman eqë¡œ value fnìœ¼ë¡œ í•˜ëŠ”ê±°ëŠ” í™˜ê²½ ë°”ë€Œë©´ ë‹¤ì‹œ ì ìš©í•´ì•¼ í•¨</li>
</ul>

<p><img src="/assets/img/2022-06-12-14.-Reinforcement-Learning-(1).md/10.png" alt="10" /></p>

<ul>
  <li>T calculate V(1) ,consider a path s1- s2-s3-s7-s11-s12</li>
</ul>

<p>s1ì— ëŒ€í•´ ê°€ì¥ í° state functionì˜ ê²°ê³¼ë¥¼ ë§Œë“œëŠ” ê°’ì„ ì·¨í•˜ë„ë¡ í–ˆë‹¤.</p>

<ul>
  <li>(assume $\gamma = 1$)
    <ul>
      <li>V(1) = R(s1, â†’) + V(2) = -1+V(2)</li>
      <li>V(2) = R(s2, â†’) + V(3) = -1+V(3)</li>
      <li>V(3) = R(s3, $\downarrow$) + V(7) = -1+V(7)</li>
      <li>V(7) = R(s7, $\downarrow$) + V(11) = -1+V(11)</li>
      <li>V(11) = R(s11, â†’) + V(12) = -1+V(12)</li>
    </ul>
  </li>
  <li>Since V(12) = 10
    <ul>
      <li>We can get V(11)=9, V(7)=8, V(3)=7, V(2) = 6, V(1) = 5</li>
    </ul>
  </li>
  <li>We can consider other path, s1-s2-s3-s4- s3-s7-s11-s12 to calculate V(1), in which case V(1) will be less than 5 14</li>
</ul>

<p><img src="/assets/img/2022-06-12-14.-Reinforcement-Learning-(1).md/11.png" alt="11" /></p>

\[V(s) = max_a(R(s,a) + \gamma V(s'))\]

<ul>
  <li>By calculating V(s) for all states
    <ul>
      <li>Agent can move to the state with larger state value</li>
    </ul>
  </li>
  <li>ì„ì˜ì˜ ì¶œë°œì ì—ì„œ state function ì»¤ì§€ëŠ” ìª½ìœ¼ë¡œ actionì„ ì·¨í•˜ë©´ ëœë‹¤
â†’ equationì„ ì´ìš©í•´ì„œ value funcitionì„ êµ¬í•œí›„ ìµœì ì˜ pathë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤</li>
</ul>

  </div><a class="u-url" href="/14.-Reinforcement-Learning-(1)" hidden></a>
</article>


      </div>
    </main><footer>
  <hr style="margin-left: 15px; color: #000 !important; background-color: #000 !important; opacity: 1 !important; width: 40px; height: .5px !important; margin-bottom: 2rem !important;">
  <div class="row m-0">
    <div class="col-12 col-md-3 col-sm-4 mb-4 mb-sm-0">
      <p>
        <a href="https://github.com/underthelights/underthelights.github.io" style="font-weight: 300">Kyuhwan Shim</a>
        <br>Up-to-date as of <span id="date">loading...</span></p>
      <i class="fas fa-location-dot mr-1"></i> Seoul is <img style="width: auto; height: 23px;" id="weather_icon">
      <span id="weather">Loading...</span>
    </div>
    <div class="col-12 col-md-9 col-sm-8">
      <p>
        <a style="font-weight: 300" href="https://linkedin.com/in/kyuhwan-shim"><i class="fab fa-linkedin" style="margin-right: 10.5px"></i>LinkedIn</a><br>
        <a style="font-weight: 300" href="https://fb.com/s.kyuhwn"><i class="fab fa-facebook" style="margin-right: 8px"></i>Facebook</a><br>
        <a style="font-weight: 300" href="https://www.instagram.com/s.kyuhwn"><i class="fab fa-instagram" style="margin-right: 10.5px"></i>Instagram</a><br>
        <a style="font-weight: 300" href="https://github.com/underthelights"><i class="fab fa-github" style="margin-right: 10.5px"></i>GitHub</a><br>
      </p>
    </div>
  </div>
</footer>

<script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.18.1/moment.min.js"></script>

<script src="/assets/js/weather.js"></script>
<script src="/assets/js/github_date.js"></script>
</body>

</html>
