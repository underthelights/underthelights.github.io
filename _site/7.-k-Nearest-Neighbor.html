<!DOCTYPE html>
<html lang="en"><head>
  
  <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
         TeX: {
         equationNumbers: {
             autoNumber: "AMS"
         }
         },
         tex2jax: {
         inlineMath: [ ['$', '$'] ],
         displayMath: [ ['$$', '$$'] ],
         processEscapes: true,
     }
     });
     MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
         alert("Math Processing Error: "+message[1]);
         });
     MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
         alert("Math Processing Error: "+message[1]);
         });
     </script>
<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
  

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <title>7. k-Nearest Neighbor âœ± Kyuhwan Shim</title>

  <link rel="stylesheet" href="/assets/css/style.css">

  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Barlow:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800&family=Noto+Sans+TC&display=swap" rel="stylesheet">

  <link href="/assets/fontawesome/all.min.css" rel="stylesheet">

  <!-- Bootstrap -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Zenh87qX5JnK2Jl0vWa8Ck2rdkQ2Bzep5IDxbcnCeuOxjzrPF/et3URy9Bv1WTRi" crossorigin="anonymous">
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-OERcA2EqjJCMA+/3y+gxIOqMEjwtxJY7qPCqsdltbNJuaOe923+mo//f6V8Qbsw3" crossorigin="anonymous"></script>
  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js'></script>

  <!-- GA -->
  
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VG8LB4J4EL"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VG8LB4J4EL');
</script>


  <!-- favicon -->
  <link rel="apple-touch-icon" sizes="57x57" href="/assets/images/main/favicon/favicon.ico">
  <link rel="apple-touch-icon" sizes="57x57" href="/assets/images/main/favicon/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/assets/images/main/favicon/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/assets/images/main/favicon/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/assets/images/main/favicon/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/assets/images/main/favicon/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/assets/images/main/favicon/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/assets/images/main/favicon/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/assets/images/main/favicon/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/images/main/favicon/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="/assets/images/main/favicon/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/images/main/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/assets/images/main/favicon/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/images/main/favicon/favicon-16x16.png">
  <link rel="manifest" href="">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/assets/images/main/favicon/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">

  <!-- Opengraph -->
  <meta property="og:type" content="website">
  <meta property="og:image" content="/assets/images/main/favicon/og.png7.-k-Nearest-Neighbor.jpg">
  <meta property="og:title" content="7. k-Nearest Neighbor | Kyuhwan Shim">
  <meta property="og:description" content="Paper overview of  et al., ">

  <!-- Google scholar -->
  
  <meta name="citation_title" content="7. k-Nearest Neighbor">
  
  <meta name="citation_publication_date" content="">
  
  <meta name="citation_conference_title" content="">
  
  <meta name="citation_pdf_url" content="https://underthelights.github.io/assets/pdf/7.-k-Nearest-Neighbor.pdf">
  
</head>
<body><header class="page-content">
  <nav class="navbar navbar-expand-md navbar-light py-4">
    <div class="container-fluid">
      <button class="navbar-toggler ms-auto" type="button" data-bs-toggle="collapse" data-bs-target="#navbarTogglerDemo01" aria-controls="navbarTogglerDemo01" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarTogglerDemo01">
        <ul class="navbar-nav ms-auto mt-4 mt-lg-0 navbar-nav-scroll">
          <li class="nav-item">
            <a class="nav-link " aria-current="page" href="/">Home</a>
          </li>
          <li class="nav-item">
            <a class="nav-link " aria-current="page" href="/news">News</a>
          </li>
          <li class="nav-item">
            <a class="nav-link " aria-current="page" href="/publication">publication</a>
          </li>
          <li class="nav-item">
            <a class="nav-link " aria-current="page" href="/project">Project</a>
          </li>
          <li class="nav-item">
            <a class="nav-link " aria-current="page" href="/oconnect">oconnect</a>
          </li>
          <li class="nav-item">
            <a class="nav-link " aria-current="page" href="/cv">CV</a>
          </li>
          <li class="nav-item dropdown">
              <a href="#" class="nav-link dropdown-toggle " data-bs-toggle="dropdown">fun</a>
              <div class="dropdown-menu">
                  <a href="/music" class="dropdown-item">music</a>
                  <a href="/artwork" class="dropdown-item">artwork</a>
              </div>
          </li>
          <li class="nav-item">
            <a class="nav-link " aria-current="page" target="_blank" rel="noopener noreferrer" href="https://underthelights.github.io/blog/">Blog<i class="fa-regular fa-arrow-up-right-from-square" style="padding-left: 5px;"></i></a>
          </li>
        </ul>
      </div>
    </div>
  </nav>
</header>

<style>
  .dropdown-toggle {
    background-color: transparent;
    border-color: #fff;
    border-style: solid;
    border-top: none;
    border-right: none;
    border-left: none;
    transition: color .15s ease-in-out, background-color .15s ease-in-out,border-color .15s ease-in-out;
  }
  .dropdown-toggle:hover {
    font-weight: 500
  }
  .dropdown:hover .dropdown-menu {
    display: block;
    margin-top: 0;
 }
 .dropdown-menu {
    --bs-dropdown-border-radius: 0 !important;
    padding-top: 0 !important;
    padding-bottom: 0 !important
 }
 .dropdown-item {
  font-size: .95rem !important;
  padding: .3rem .75rem !important;
 }
 .dropdown-item:active {
  background-color: #999 !important
 }
</style><main class="page-content" aria-label="Content">
      <div class="wrapper">
        <style>
  h1,
  h2,
  h3,
  h4,
  h5,
  h6 {
    
      font-family: 'Arial', sans-serif;
      /* Use a modern font */
      margin-top: 20px;
      margin-bottom: 10px;
  }
  /* í¬ìŠ¤íŠ¸ í—¤ë”ì— ì ìš©ë˜ëŠ” ì—¬ë°± ì œê±° */
  .post-header, h1, h2, h3, h4, h5, h6 {
      margin-left: 0 !important; 
      padding-left: 0 !important;
  }


  .post-title {
      font-size: 2em; /* í°íŠ¸ í¬ê¸° ì¦ê°€ */
      font-weight: bold; /* ë³¼ë“œì²´ */
      color: #333; /* ìƒ‰ìƒ ë³€ê²½ */
      box-shadow: inset 0 -20px 0 #bbb7e8;
      max-width: max-content;
    }

  /* Updated styling for h1 */
  h1 {
    font-size: 1.5em;
    /* Increase font size for main titles */
    box-shadow: inset 0 -10px 0 #bbb7e8;
    max-width: max-content; 
    font-weight: bold; /* ë³¼ë“œì²´ */
    border-bottom: none;
    /* Remove bottom border */
    padding-bottom: 0;
    /* Adjust padding if needed */
  }

  h2 {
    font-size: 1.2em;
    margin-left: none;
    font-weight: bold; /* ë³¼ë“œì²´ */
    max-width: max-content; 
    background-color: #cdcbe9;
  }

  h3 {
    font-size: 1.1em;
    max-width: max-content; 
    
    max-width: max-content; 
    background-color: #bbb7e8;
  }

  h4 {
    font-size: 0.75em;
    color: #888888;
  }

  h5 {
    font-size: 0.5em;
    color: #a6a6a6;
  }

  h6 {
    font-size: 1em;
    color: #bcbcbc;
  }

  /* Add some additional styling if needed */
  .post-content {
    margin-left: 20px; /* ì™¼ìª½ ì—¬ë°± ì¶”ê°€ */
    /* margin-right: 20px; ì˜¤ë¥¸ìª½ì— TOC ë„ˆë¹„ + ì—¬ë°± ë§Œí¼ ì¶”ê°€ */
    line-height: 1.6;/* Improve readability */
    color: #333;/* Dark grey color for text */
  }
  /* Category Chart Style */
  .category-chart {
    font-family: 'Arial', sans-serif;
    /* width: 100%; */
    /* height: 100px; Adjust as needed */
  }

  .category-list li {
    display: inline-block;
    margin-right: 20px;
  }
  /* ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼ */
  img {
    display: block; /* ì´ë¯¸ì§€ë¥¼ ë¸”ë¡ ë ˆë²¨ë¡œ ì„¤ì • */
    width: 50%; /* ë˜ëŠ” ì›í•˜ëŠ” ë„ˆë¹„ */
    height: auto; /* ë¹„ìœ¨ ìœ ì§€ */
    margin-bottom: 5px; /* ì´ë¯¸ì§€ì™€ ìº¡ì…˜ ì‚¬ì´ì˜ ê°„ê²© */
    text-align: center;
  }

  /* ì´ë¯¸ì§€ ìº¡ì…˜ ìŠ¤íƒ€ì¼ë§ */
  .em {
    color: #757575;
    font-size: 0.8em;
    
    /* margin-top: 5px; */
    display: block; /* ìº¡ì…˜ì„ ë¸”ë¡ ìš”ì†Œë¡œ ì„¤ì •, ì´ë¯¸ì§€ ì•„ë˜ë¡œ ê°•ì œ ë°°ì¹˜ */
    text-align: center;
    margin-bottom: 5px;
  }
  /* Blockquote ìŠ¤íƒ€ì¼ */
  blockquote {
      margin-left: 20px;
      border-left: 1.5px solid #ccc; /* ì¢Œì¸¡ ì„  */
      border-top: 1.5px solid #ccc; /* ì¢Œì¸¡ ì„  */
      border-right: 1.5px solid #ccc; /* ì¢Œì¸¡ ì„  */
      border-bottom: 1.5px solid #ccc; /* ì¢Œì¸¡ ì„  */

      padding-left: 15px;
      color: #666; /* ê¸€ì ìƒ‰ìƒ */
  }



</style>

<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <!-- Table of Contents Container -->
<div class="toc-container">
    <nav class="toc">
      <strong>Table of Contents</strong>
      <!--  -->
      <!-- Jekyll TOC Liquid Code -->
      <ul><li><a href="#k-nearest-neighbor-classifier">k-Nearest Neighbor Classifier</a></li><li><a href="#distance-metric">Distance Metric</a><ul><li><a href="#distance">Distance</a></li><li><a href="#equations-of-selected-distance-functions">equations of selected distance functions</a></li><li><a href="#value-difference-metric-vdm">Value difference metric (VDM)</a></li></ul></li><li><a href="#problem-with-euclidean-distance">Problem with Euclidean distance</a></li><li><a href="#behavior-in-the-limit">Behavior in the limit</a></li><li><a href="#standardization">Standardization</a></li><li><a href="#efficient-searching">Efficient searching</a></li><li><a href="#choosing-k">Choosing k</a></li><li><a href="#cross-validation">Cross-validation</a></li><li><a href="#condensing">Condensing</a><ul><li><a href="#condensed-nearest-neighbor-cnn">Condensed Nearest Neighbor (CNN)</a></li></ul></li><li><a href="#condensation">Condensation</a><ul><li><a href="#voronoi-diagram-êµ¬ì„±í•˜ëŠ”-ë°©ë²•">Voronoi Diagram êµ¬ì„±í•˜ëŠ” ë°©ë²•</a></li></ul></li></ul>

      <!-- <ul><li><a href="#k-nearest-neighbor-classifier">k-Nearest Neighbor Classifier</a></li><li><a href="#distance-metric">Distance Metric</a><ul><li><a href="#distance">Distance</a></li><li><a href="#equations-of-selected-distance-functions">equations of selected distance functions</a></li><li><a href="#value-difference-metric-vdm">Value difference metric (VDM)</a></li></ul></li><li><a href="#problem-with-euclidean-distance">Problem with Euclidean distance</a></li><li><a href="#behavior-in-the-limit">Behavior in the limit</a></li><li><a href="#standardization">Standardization</a></li><li><a href="#efficient-searching">Efficient searching</a></li><li><a href="#choosing-k">Choosing k</a></li><li><a href="#cross-validation">Cross-validation</a></li><li><a href="#condensing">Condensing</a><ul><li><a href="#condensed-nearest-neighbor-cnn">Condensed Nearest Neighbor (CNN)</a></li></ul></li><li><a href="#condensation">Condensation</a><ul><li><a href="#voronoi-diagram-êµ¬ì„±í•˜ëŠ”-ë°©ë²•">Voronoi Diagram êµ¬ì„±í•˜ëŠ” ë°©ë²•</a></li></ul></li></ul> -->
    </nav>
</div>

<style>
    /* TOC ìŠ¤íƒ€ì¼ */
.toc-container {
  position: fixed;
  right: 10px;
  top: 100px;
  z-index: 1000;
  /* max-width: 50px; ê°€ë¡œ ë„ˆë¹„ ì¡°ì •, í•„ìš”ì— ë”°ë¼ ê°’ì„ ë³€ê²½í•˜ì„¸ìš” */
  font-size: 0.75rem;
}

.toc {
  border: 1px solid #ddd;
  padding: 10px;
  border-radius: 5px;
  background-color: white;
  box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
  max-width: 200px; /* ê°€ë¡œ ë„ˆë¹„ ì¡°ì •, í•„ìš”ì— ë”°ë¼ ê°’ì„ ë³€ê²½í•˜ì„¸ìš” */
}


.toc strong {
  display: block;
  margin-bottom: 10px;
}

.toc ul {
  list-style: none;
  padding: 0;
  margin: 0;
}

.toc ul li a {
  text-decoration: none;
  color: #007bff;
  display: block;
  padding: 5px 0;
}

.toc ul li a:hover,
.toc ul li a.active { /* ì¶”ê°€ëœ active í´ë˜ìŠ¤ ìŠ¤íƒ€ì¼ */
  font-weight: bold;
  /* box-shadow: inset 0 -10px 0 #bbb7e8; */
  background-color: #bbb7e8;
}



  button {
    padding: 5px 10px;
    /* ìƒí•˜ 10px, ì¢Œìš° 20px íŒ¨ë”©ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì£¼ë³€ ì—¬ìœ  ê³µê°„ ì¶”ê°€ */
    font-size: 0.87rem;
    /* ê¸€ì í¬ê¸° */
    color: white;
    /* ê¸€ì ìƒ‰ìƒ */
    background-color: #007bff;
    /* ë°°ê²½ ìƒ‰ìƒ */
    border: none;
    /* í…Œë‘ë¦¬ ì œê±° */
    border-radius: 5px;
    /* ëª¨ì„œë¦¬ ë‘¥ê¸€ê²Œ */
    cursor: pointer;
    /* ì»¤ì„œ ëª¨ì–‘ ë³€ê²½ */
    transition: background-color 0.3s;
    /* í˜¸ë²„ íš¨ê³¼ë¥¼ ìœ„í•œ ì „í™˜ ì„¤ì • */
    text-align: center;
    /* ê¸€ìë¥¼ ë²„íŠ¼ ì¤‘ì•™ì— ìœ„ì¹˜ */
    display: inline-block;
    /* ì¸ë¼ì¸ ë¸”ë¡ ìš”ì†Œë¡œ ì„¤ì •í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ í…ìŠ¤íŠ¸ ì¤‘ì•™ ì •ë ¬ */
    line-height: normal;
    /* ê¸°ë³¸ ë¼ì¸ ë†’ì´ ì„¤ì • */
    vertical-align: middle;
    /* ìˆ˜ì§ ë°©í–¥ìœ¼ë¡œ ì¤‘ì•™ ì •ë ¬ */
    margin-top: 5px;
  }

  button:hover {
    background-color: #0056b3;
    /* í˜¸ë²„ ì‹œ ë°°ê²½ ìƒ‰ìƒ ë³€ê²½ */
  }


  /* reset base styles */
  * {
    box-sizing: border-box;
    margin: 0;
    padding: 0;
  }

  /* page header */
  header {
    margin-bottom: 2rem;
    padding-left: 6.5rem;
  }

  header h1 {
    font-size: 1.5rem;
  }

  header p {
    margin: .5rem 0;
    font-size: 1rem !important
  }

  main b {
    font-weight: 500
  }

  /* normal body content */
  h2 {
    font-size: 1.1rem;
    margin-bottom: 0.75rem;
    margin-left: 6.5rem;
    text-transform: uppercase;
  }

  h3 {
    border-bottom: 1px solid black;
    font-size: .9rem;
    margin: 1rem 0 .5rem 6.5rem
  }

  p {
    margin-bottom: 0.5rem;
  }

  a {
    color: inherit;
    /*#0000ee;*/
  }

  section {
    margin-bottom: 3rem;
  }

  /* misc */
  .pdf {
    font-size: .9rem !important;
    font-weight: 300;
    margin-left: 1.5rem;
    white-space: nowrap;
  }

  .pdf i {
    margin-right: .1rem;
  }

  .material {
    font-size: small;
    margin-left: .5rem;
  }

  :global(i) {
    padding-right: 4px !important
  }

  /* dated entries */
  .dated-entry {
    display: flex;
    flex-flow: row wrap;
    position: relative;
    margin-bottom: 1rem;
  }

  .dated-date {
    width: 6.5rem;
    text-align: right;
    padding-top: .15rem;
    padding-right: 1.5rem;
    font-size: .8rem
  }

  .dated-content {
    width: calc(100% - 6.5rem);
    font-size: .95rem
  }

  .oneline-entries {
    margin-bottom: 0.5rem;
  }

  .oneline-entries .dated-entry {
    margin-bottom: 0;
  }

  /* hide extra awards info for now, not sure what to include */
  #awards em {
    display: none;
  }

  .author-tooltip {
    font-weight: 400;
    font-size: .8rem !important;
    text-align: center;
  }

  /* on narrow displays, make the font smaller */
  @media (max-width: 480px) {
    html {
      font-size: 14px;
    }
  }

  /* when printing, make the font smaller and the page full-width */
  @media print {
    html {
      font-size: 12px;
    }

    main {
      margin-top: 0;
      max-width: 100%;
    }
  }

</style>

<script>
    document.addEventListener('scroll', function() {
      var sections = document.querySelectorAll('section'); // ì„¹ì…˜ ì„ íƒì ìˆ˜ì •
      var menu_links = document.querySelectorAll('.toc a'); // TOC ë§í¬ ì„ íƒì ìˆ˜ì •
    
      var fromTop = window.scrollY;
    
      sections.forEach(function(section) {
        if (section.offsetTop <= fromTop && section.offsetTop + section.offsetHeight > fromTop) {
          menu_links.forEach(function(link) {
            if (section.getAttribute('id') && link.getAttribute('href').includes(section.getAttribute('id'))) {
              link.classList.add('active');  // í˜„ì¬ ì„¹ì…˜ì˜ TOC ë§í¬ì— 'active' í´ë˜ìŠ¤ ì¶”ê°€
            } else {
              link.classList.remove('active'); // ë‹¤ë¥¸ ëª¨ë“  ë§í¬ì—ì„œ 'active' í´ë˜ìŠ¤ ì œê±°
            }
          });
        }
      });
    });
    </script>
    

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">7. k-Nearest Neighbor</h1>
    <p class="post-meta"><time class="dt-published" datetime="2023-05-10T00:00:00+02:00" itemprop="datePublished">
        May 10, 2023
      </time></p>
    <!-- íƒœê·¸ì™€ ì¹´í…Œê³ ë¦¬ í‘œì‹œ -->
    <div class="post-categories">
      
      <strong><span>ğŸ“š Categories:</span></strong>
      
      <a href="blog-categories-notes">Notes</a>
      
      
    </div>

    <div class="post-tags">
      
      <strong><span>ğŸ·ï¸ Tags:</span></strong>
      
      <a href="blog-tags-ml">ML</a>
      
      
    </div>


  </header>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h1 id="k-nearest-neighbor-classifier">k-Nearest Neighbor Classifier</h1>

<ul>
  <li>perceptron : linear classifier</li>
  <li>SVM : linear, nonlinear classifier
    <ul>
      <li>given data â†’ ë¶„ë¥˜í•˜ëŠ” hyperplaneë¥¼ êµ¬í•œë‹¤.</li>
      <li>GDë¡œ ê³„ì‚°í•œë‹¤ : iteration ìˆ˜ì²œ~ìˆ˜ë°± epoch ì—°ì‚°ì„ ìˆ˜í–‰í•œë‹¤</li>
      <li>(1) phi fnìœ¼ë¡œ ê³ ì°¨ì› mapping data ì²˜ë¦¬ ê°€ëŠ¥
        <ul>
          <li>kernel trick ($\epsilon$â†’0)</li>
        </ul>
      </li>
      <li>(2) soft margin</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/0.png" alt="0" /></p>

<ul>
  <li>Store all training samples $(x_i, y_i)$ - ëª¨ë“  ë°ì´í„° ì €ì¥
    <ul>
      <li>í•™ìŠµ data ì €ì¥í•˜ë©´ ëì´ë‹¤ (extra data task ë¶ˆí•„ìš”)</li>
    </ul>
  </li>
  <li>Nearest Neighbor classifier
    <ul>
      <li>Given a test sample $x_t$, locate the nearest training sample $(x_{n1}, y_{n1})$,</li>
      <li>then assign $y_{n1}$as the class label of $x_t$</li>
      <li></li>
    </ul>
  </li>
  <li>k-Nearest Neighbor classifier
    <ul>
      <li>Given a test sample $x_t$, locate the k-nearest training samples $(x_{n1}, y_{n1}), â€¦,(x_{nk}, y_{nk}) $ then assign <strong>majority class label</strong> of $y_{n1}, â€¦ y_{nk}$ to $x_t$
        <ul>
          <li><strong>majority class label</strong>  : majority voting, nearst sample labeling algorithm</li>
        </ul>
      </li>
      <li>Take mean of , if they are real valued $\hat{f} = \frac 1 k \Sigma_{i=1}^{k} f(x_{ni})$</li>
      <li>Also called as <strong>Instance</strong> based learning</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/1.png" alt="1" /></p>

<ul>
  <li>test ì‹œì ì—ì„œ data ë“¤ì–´ì˜¤ë©´ í•´ë‹¹ dataì™€ near sample íŒë‹¨ : <strong>sampleê°„ ê±°ë¦¬ ê³„ì‚°</strong>
    <ul>
      <li>
        <table>
          <tbody>
            <tr>
              <td>$L^2$-norm : $\sqrt{\Sigma_{d=1}^{D}</td>
              <td>x_{td} - x_{nd}</td>
              <td>^2}$</td>
            </tr>
          </tbody>
        </table>
      </li>
      <li>test dataì— ëŒ€í•´ ê±°ë¦¬ë¥¼ ê³„ì‚°í•  ë•Œ test sampleê³¼ nearí•œì§€ distance ê³„ì‚°í•œë‹¤.</li>
    </ul>
  </li>
  <li>sample dimensionì´ ì¦ê°€í•˜ë©´ â†’ calculation cost ì¦ê°€
    <ul>
      <li>ëª¨ë“  sampleë“¤ë¼ë¦¬ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ë©´ - dimension ì¦ê°€ë˜ë©´</li>
    </ul>

    <p>(í•´ê²°) kNN Optimization</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  - í•™ìŠµ ì‹œ ê³„ì‚° ì ê²Œ storage í¬ê²Œ : ì–´ë–»ê²Œ saveí•˜ëŠ”ê°€?
  - test ì‹œ ê³„ì‚° ë§ì´ :  ì–´ë–»ê²Œ ì¤„ì´ëŠ”ê°€?
</code></pre></div>    </div>
  </li>
  <li>When to consider
    <ul>
      <li>Vector features</li>
      <li>~Less than 20 attributes (=20 dim)</li>
      <li>Sufficient amount of training data</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/2.png" alt="2" /></p>

<ul>
  <li><strong>Advantages</strong>
    <ul>
      <li><u>**Training is very fast :**</u> feature extraction &amp; save</li>
      <li>Learn complex target functions</li>
      <li>Donâ€™t lose information</li>
    </ul>
  </li>
  <li><strong>Disadvantages</strong>
    <ul>
      <li>Slow at query time ( â‡’ test time)
        <ul>
          <li><strong>train ì—ì„œì˜ ì—°ì‚°ì´ ë§ì€ ê²ƒì´ ì¢‹ì„ê¹Œ?</strong> ì•„ë‹ˆë©´ test ì—ì„œì˜ ì—°ì‚°ì´ ë§ì€ ê²ƒì´ ì¢‹ì„ê¹Œ?
            <ul>
              <li>testí•˜ê¸° ì „ enough timeìœ¼ë¡œ ì €ì¥ (sample ê·¸ëŒ€ë¡œ ì €ì¥)</li>
              <li>train offline / test online,offline</li>
              <li><strong>soâ†’ test ì‹œì  ì—°ì‚°ì´ ì ì€ ê²ƒì´ ìœ ë¦¬í•¨</strong></li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Requires large storage</li>
      <li>Not robust against irrelevant <strong>attributes or outliers</strong>
        <ul>
          <li>SVM, Perceptron : boundaryì— í¬ê²Œ ì˜í–¥ì´ ì—†ìŒ</li>
          <li>kNN : test sampel decisionì— ë³€í™” ê°€ëŠ¥í•¨</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h1 id="distance-metric">Distance Metric</h1>

<ul>
  <li>Search operation is expensive with high dimensions</li>
</ul>

<h2 id="distance">Distance</h2>

<p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/3.png" alt="3" /></p>

<ul>
  <li>ëª¨ë“  classify / regressì—ì„œ ì¤‘ìš”í•¨
    <ul>
      <li>decision tree : nominal data â†’ distance ë¶ˆí•„ìš”</li>
      <li>ê° feature ê°’ë“¤ì´ ì„œë¡œ ë‹¤ë¥¸ wë¥¼ ê°€ì§ˆ ìˆ˜ ìˆìŒ
        <ul>
          <li>ex. age, height</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>distance = 1/similarity</li>
</ul>

<p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/4.png" alt="4" /></p>

<p>feature vectorí•˜ë‚˜ dimensionì€ ì˜ë¯¸ê°€ ì—†ìœ¼ë©°, ì „ì²´ê°€ ëª¨ì—¬ ì••ì¶•ëœ í˜•íƒœë¡œ í‘œí˜„ëœë‹¤.</p>

<h2 id="equations-of-selected-distance-functions">equations of selected distance functions</h2>

<p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/5.png" alt="5" /></p>

<ul>
  <li></li>
</ul>

<h2 id="value-difference-metric-vdm">Value difference metric (VDM)</h2>

<ul>
  <li>attribute class í†µí•´ íŒë‹¨ â†’ ë™ì¼ class ì†í•˜ëŠ” ê²ƒì´ ê´€ì°°ë˜ë©´ attributeê°€ ë” ê°€ê¹ë‹¤ê³  ë³¸ë‹¤.
    <ul>
      <li>ex. R-Bê°€ ë” ë§ì´ ê°™ì€ classë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©´ â†’ R-B &gt; R-G</li>
    </ul>
  </li>
  <li>Providing distance measurements for nominal attributes
    <ul>
      <li>$vdm_a(x,y) = \Sigma_{c=1}^C (\frac{N_{a,x,c}}{N_{a,x}}-\frac{N_{a,y,c}}{N_{a,y}})^2$</li>
      <li>ğ‘µğ’‚,ğ’™ : # times attribute a had value x
  ğ‘µğ’‚,ğ’™,ğ’„: # times attribute a had value x and class was c
  ğ‘ª : # output classes</li>
      <li>a : color / x : big / y : medium, small ??</li>
    </ul>
  </li>
  <li>Two values are considered closer if they have more similar classifications, i.e., if they have more similar correlations with the output classes</li>
</ul>

<h1 id="problem-with-euclidean-distance">Problem with Euclidean distance</h1>

<ul>
  <li>High dimensional data
    <ul>
      <li>dimension : color, length, weightâ€¦ë“±ì˜ data attribute</li>
      <li>ë” ë§ì€ attributeë¥¼ ì¶”ê°€í• ìˆ˜ë¡ performance ìƒìŠ¹</li>
      <li>ê·¸ëŸ¬ë‚˜ ë„ˆë¬´ ë§ì´ feature/ attribute ì¦ê°€ì‹œí‚¤ë©´ dimì´ ë„ˆë¬´ ë§ì´ ì¦ê°€í•˜ì—¬ curse of dimensionalityì— ë¹ ì§ˆ ìˆ˜ ìˆë‹¤
        <ul>
          <li>dataê°€ ê³ ì°¨ì›ì¼ìˆ˜ë¡ ì·¨ê¸‰ì´ ì–´ë ¤ì›€
  dataì— ê´€ë ¨í•˜ì—¬ ì•Œì•„ì•¼ í•  ì •ë³´ê°€ ë§ì€ë° ì˜ í™œìš©ì¹˜ ëª»í•˜ë©´ classifier ì„±ëŠ¥ ì €í•˜ë¨</li>
        </ul>
      </li>
      <li>(Number of samples - available info) ì–‘ì´ ë§ê³  + ì •í™•í•œ ì •ë³´ë¼ë©´ dimensionì´ ë†’ì•„ë„ ê´œì°®ë‹¤.</li>
    </ul>
  </li>
  <li>Can produce counter-intuitive results</li>
  <li>Shrinking density â€“ sparsification effect
    <ul>
      <li>data dimensionì„ ë‚®ì¶”ì–´ ì²˜ë¦¬í•˜ë©´ dataê°€ sparseí•œ í˜•íƒœ</li>
    </ul>
  </li>
  <li>dê°€ ê°™ë‹¤ê³  data featureë¥¼ ì˜ ë°˜ì˜í•˜ëŠ”ì§€ì— ëŒ€í•´ì„œëŠ” ì˜ ê³ ë ¤í•´ë´ì•¼ í•¨
    <ul>
      <li>ê° feature dimesionì´ data significanceë¥¼ ë‚˜íƒ€ëƒ„ â†’ featureê±°ë¦¬ë¥¼ ì¸¡ì •í•˜ëŠ” ê²ƒì´ ìœ ì‚¬ì„±ê³¼ ì°¨ì´ì ì„ ëœ ë°˜ì˜í•  ìˆ˜ë„ ìˆìŒ</li>
      <li>binary feature : ê³¼ì—° dê°€ ë™ì¼í•œ ê°’ì´ë¼ê³  data featureë¥¼ ì˜ ë‚˜íƒ€ë‚´ëŠ” ê²ƒì¼ê¹Œ?</li>
      <li>1 1 1 1 1 1 1 1 1 1 1 0
  0 1 1 1 1 1 1 1 1 1 1 1
  d = 1.4142</li>
      <li>1 0 0 0 0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0 0 0 0 1
  d = 1.4142</li>
    </ul>
  </li>
  <li>hamming distance
    <ul>
      <li>ê° bit ì‚¬ì´ ê°™ì€/ë‹¤ë¥¸ bit ë‚˜íƒ€ë‚˜ëŠ”ì§€ íŒë‹¨</li>
    </ul>
  </li>
  <li>histogram intersection
    <ul>
      <li>
        <p>$\Sigma_i \min(h_{1i}, h_{2i})$</p>

        <p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/6.png" alt="6" /></p>
      </li>
    </ul>
  </li>
</ul>

<h1 id="behavior-in-the-limit">Behavior in the limit</h1>

<ul>
  <li>ì„±ëŠ¥
    <ul>
      <li>kNN ($\epsilon$ up) &lt; optimal classifier ($\epsilon$ down)</li>
    </ul>
  </li>
  <li>$\epsilon^*(x) $ <strong>:</strong> Error of optimal prediction</li>
  <li>$\epsilon_{NN}(x) $ : Error of nearaest neighbor</li>
</ul>

<p>Theorem :</p>

\[\lim_{n\rightarrow \inf} \leq 2\epsilon^*\]

<ul>
  <li>proof:
    <ul>
      <li>$p_+$ : dataê°€ (+)ì¼ í™•ë¥ , $p_{NN\in(-)}$ : nearest neighborì´ (-)ì¼ í™•ë¥ </li>
      <li>$\epsilon_{NN} = p_+p_{NN\in(-)}+p_-p_{NN\in(+)} = p_+(1-p_{NN\in(+) })+(1-p_+)p_{NN\in(+)} $
        <ul>
          <li>$\epsilon_{NN} \sim\epsilon_{+} $ : Nearest Neighborê³¼ optimalí•œ sampleì˜ ê²°ê³¼ê°€ ë™ì¼í•˜ë‹¤</li>
        </ul>
      </li>
      <li>$\lim_{n \rightarrow \infty} p_{NN\in (+)} = p_+$$lim_{n \rightarrow \inf} p_{NN\in (+)} = p_+$</li>
      <li>$\lim_{n \rightarrow \inf} p_{NN\in (-)} = p_-$</li>
      <li>$\lim_{n \rightarrow \inf} \epsilon_{NN} = p_+(1-p_+) + (1-p_+)p_+ = 2p_+(1-p_+) = 2\epsilon^<em>(1-\epsilon^</em>)\leq2 \epsilon^*$
        <ul>
          <li>$2p_+(1-p_+)$
            <ul>
              <li>prediction : (+) or (-)</li>
              <li>$p_+$ê°€ ë§ìœ¼ë©´ $(1-\epsilon^<em>)$ ë§ê³  $\epsilon^</em>$ í‹€ë¦¼</li>
              <li>$p_+$ê°€ ë§ìœ¼ë©´ $(1-\epsilon^<em>)$ í‹€ë¦¬ê³  $\epsilon^</em>$ ë§ìŒ</li>
            </ul>
          </li>
          <li>$\epsilon^* \in [0,1]$</li>
        </ul>
      </li>
      <li>NN Classifier can have up to twice as much error of <strong>optical error</strong>
        <ul>
          <li>= Bayesian Classifier</li>
          <li>Samplingí•  ë•Œ íŠ¹ì • dë³´ê³  sample â†’ ì „ì²´ population know</li>
          <li>â†’ ì „ì²´ population ì •ë³´ê°€ì§€ê³  classifierë¥¼ ìƒì„±í•˜ë©´ classifier error : optimal classification errorì´ê³ </li>
          <li>ìš°ë¦¬ê°€ ì–»ì„ ìµœì†Œì˜ error â†’ optimal classifier</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Theorem :</p>

\[\lim_{n\rightarrow \infty, k \rightarrow \infty, \frac k n \rightarrow 0 } \leq \epsilon^*\]
  </li>
</ul>

<h1 id="standardization">Standardization</h1>

<ul>
  <li>Transform raw feature values into z-scores $z_{ij} = \frac{x_{ij} - \mu_j}{\sigma_j}$
    <ul>
      <li>$x_{ij}$ is the ith sample and jth feature (dimension)</li>
      <li>$\mu_j$ is the average of all for feature</li>
      <li>$\sigma_j$ is the standard deviation of all for feature</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/7.png" alt="7" /></p>

<h1 id="efficient-searching">Efficient searching</h1>

<ul>
  <li>sample ì£¼ë³€ì„ í™•ì¸í•´ì•¼ í•¨ : ì–´ë– í•œ data ì£¼ë³€ì— ì¡´ì¬í• ì§€</li>
  <li>KD trees
    <ul>
      <li>
        <p>nê°œ KD Tree êµ¬ì„±í•˜ë©´ - $\epsilon \downarrow$ : ê° class score, $w_{sum}$ê³„ì‚°</p>

        <p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/8.png" alt="8" /></p>
      </li>
    </ul>
  </li>
  <li>Choose dimension</li>
  <li>Choose pivot (median)</li>
  <li>Split data, repeat</li>
  <li></li>
</ul>

<p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/9.png" alt="9" /></p>

<p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/10.png" alt="10" /></p>

<p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/11.png" alt="11" /></p>

<h1 id="choosing-k">Choosing k</h1>

<ul>
  <li>Choosing the value of k:
    <ul>
      <li>If k is too small, sensitive to noise points</li>
      <li>If k is too large, neighborhood may include points from other classes</li>
    </ul>
  </li>
  <li>Rule of thumb:
k = sqrt(N)
N: number of training samples</li>
  <li>Use N fold cross validation â€“ Pick k to minimize the cross validation error</li>
  <li>For each of N test example
    <ul>
      <li>Find its k nearest neighbors</li>
      <li>Make a classification based on these k neighbors</li>
      <li>Calculate classification error</li>
      <li>Output average error over all examples</li>
    </ul>
  </li>
  <li>Use the k that gives lowest average error on the training data
    <ul>
      <li>ì´ë¡ ì ìœ¼ë¡œ $k \uparrow$ì´ë©´ smootherí•´ì§</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/12.png" alt="12" /></p>

<ul>
  <li>Bayes-optimal boundary given true generating model
    <ul>
      <li>ideal case : $k, n \rightarrow \infty$, $\frac k n \rightarrow 0$, $\epsilon^* \leq \epsilon_{kNN}\leq2\epsilon^*$</li>
    </ul>

\[\lim_{n\rightarrow \infty, k \rightarrow \infty, \frac k n \rightarrow 0 } \leq \epsilon^*\]

    <p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/13.png" alt="13" /></p>
  </li>
  <li>As number of training <u>samples</u> $\rightarrow \infty$, and k becomes large, k-Nearest Neighbor classifier shows performance as good as that of Bayes classifier</li>
</ul>

<h1 id="cross-validation">Cross-validation</h1>

<p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/14.png" alt="14" /></p>

<ul>
  <li>train errorê°€ ë‚®ì•„ì§€ëŠ”ê²Œ ë¬´ì‘ì • ì¢‹ì§€ëŠ” ì•Šì„ ìˆ˜ ìˆë‹¤ (overfitting)</li>
</ul>

<h1 id="condensing">Condensing</h1>

<ul>
  <li>
    <p>Aim is to reduce the number of training samples</p>

    <p>ë” ì‘ì€ datasetìœ¼ë¡œì˜ ì••ì¶•</p>
  </li>
  <li>Retain only the samples that are needed to define the decision boundary</li>
  <li>Decision Boundary Consistent â€“ a <strong>subset</strong> whose nearest neighbor decision boundary is identical to the boundary of the entire training set
    <ul>
      <li>ì „ì²´ original dataì™€ ë™ì¼í•œ boundary êµ¬í•´ì§</li>
    </ul>
  </li>
  <li>Minimum Consistent Set â€“ the <strong>smallest subset</strong> of the training data that correctly classifies all of the original training data
    <ul>
      <li>ê°€ì¥ ì‘ì€ Sample sel</li>
    </ul>
  </li>
  <li>
    <p>Original data</p>

    <p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/15.png" alt="15" /></p>

    <ul>
      <li>decision boundary êµ¬ì„± Sampleë§Œì„ ë‚¨ê²¨ ì´ dataë§Œì„ ë‚¨ê¸´ë‹¤.</li>
      <li>2,3ê°œ ì”© ì €ì¥í•´ë„ boundaryê°€ ìœ ì§€ëœë‹¤.</li>
      <li>ì „ì²´ Datasetì„ í™œìš©í•´ë„ decision boundaryëŠ” ë™ì¼í•˜ê²Œ êµ¬í•´ì§„ë‹¤.</li>
    </ul>
  </li>
  <li>
    <p>Condensed data</p>

    <p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/16.png" alt="16" /></p>
  </li>
  <li>
    <p>Minimum Consistent Set</p>

    <p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/17.png" alt="17" /></p>
  </li>
</ul>

<h2 id="condensed-nearest-neighbor-cnn">Condensed Nearest Neighbor (CNN)</h2>

<ul>
  <li>iteration ìµœì†Œ dataë¡œ errorless êµ¬í•˜ê¸°??
    <ol>
      <li>Initialize subset with a single (or k) training example</li>
    </ol>
    <ol>
      <li>í•˜ë‚˜ì˜ Dataë¥¼ ì„ì˜ë¡œ ì¶”ì¶œ
        <ol>
          <li>Classify all remaining samples using the subset, and transfer any incorrectly classified samples to the other subset</li>
        </ol>
      </li>
      <li>ê·¸ Dataë¥¼ ì´ìš©í•˜ì—¬ NN â†’ $\epsilon$ì´ ë‚˜ì˜¤ëŠ” ì„ì˜ì˜ Data ì„ íƒ
        <ol>
          <li>Return to 2 until no transfers occurred or the subset is full</li>
        </ol>
      </li>
      <li>data, error êµ¬í•˜ê¸°</li>
    </ol>
  </li>
</ul>

<p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/18.png" alt="18" /></p>

<p>â†’ ì´ˆê¸° Data ì„ íƒì— ë”°ë¼ decision boundary ë³€í™”</p>

<ul>
  <li>kNN â†’ decision boundary
    <ul>
      <li>ì–´ë–¤ groupì— test data ì†í•˜ëŠ”ì§€ í™•ì¸</li>
    </ul>
  </li>
</ul>

<h1 id="condensation">Condensation</h1>

<ul>
  <li>Each cell contains one sample, and every location within the cell is closer to that sample than to any other sample.</li>
  <li>A <strong>Voronoi diagram</strong> divides the space into such cells.
    <ul>
      <li>êµ¬íšìœ¼ë¡œ ë‚˜ëˆ„ê³  boundaryì— ì˜í–¥ ì—†ëŠ” Sampleì„ ì œê±°í•˜ëŠ” ë°©í–¥</li>
    </ul>
  </li>
  <li>Every query point will be assigned the classification of the sample within that cell. The decision boundary separates the class regions based on the 1-NN decision rule.</li>
  <li>Knowledge of this boundary is sufficient to classify new points.</li>
  <li>The boundary itself is rarely computed; many algorithms seek to retain only those points necessary to generate an identical boundary.</li>
</ul>

<p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/19.png" alt="19" /></p>

<ul>
  <li>data ì£¼ì–´ì§€ë©´ ê·¸ë¡œë¶€í„° ì–»ëŠ” 1NN boundaryê°€ ìœ ì¼í•˜ê²Œ ê²°ì •ë¨
    <ul>
      <li>â†’ train data ì „ë¶€ ì €ì¥í•˜ì§€ ì•Šì•„ë„ boundaryë§Œ ì €ì¥í•˜ë©´ ë¨</li>
    </ul>
  </li>
</ul>

<h2 id="voronoi-diagram-êµ¬ì„±í•˜ëŠ”-ë°©ë²•">Voronoi Diagram êµ¬ì„±í•˜ëŠ” ë°©ë²•</h2>

<p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/20.png" alt="20" /></p>

<ul>
  <li><strong>Delaunay triangulation (Delone triangulation)</strong> for a given set P of discrete points is a triangulation DT(P) such that no point in P is inside the <strong>circumcircle</strong> of any triangle in DT(P)</li>
  <li>Circumcircle (circumscribed circle) of a polygon is a circle that passes through all the vertices of the polygon</li>
  <li>ì–´ë– í•œ ì ë„ í•´ë‹¹ Circle ë‚´ ë“¤ì–´ê°€ì§€ ì•Šë„ë¡, ë‹¤ê°í˜•ì„ ë‘˜ëŸ¬ì‹¼ ì› í˜•ì„±
    <ul>
      <li>â†’ì„¸ ì ì„ ë‘˜ëŸ¬ì‹¼ ì›, ì› ë‚´ë¶€ì— ì£¼ì–´ì§„ ì ì„ í¬í•¨í•˜ë©´ ì•ˆ ë˜ëŠ” í˜•íƒœë¡œ</li>
    </ul>
  </li>
  <li>Avoid sliver triangles. (maximize angles of triangles) 
ì˜ˆê°ì‚¼ê°í˜•ì„ í”¼í•˜ê³ , ê°ë„ ìµœëŒ€í™”
    <ul>
      <li>
        <p>Delaunay triangulation is not unique</p>

        <p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/21.png" alt="21" /></p>
      </li>
    </ul>
  </li>
  <li>Circumcenters of Delaunay triangles are the vertices of the Voronoi diagram</li>
  <li>If two triangles share an edge in the Delaunay triangulation, their circumcenters are to be connected with an edge in the Voronoi tesselation</li>
  <li>ë°©ë²• : delaunary triangle ë§Œë“¤ê³  â†’ circumcircleì˜ ê°€ìš´ëƒì  pt â†’ centered point ì—°ê²°</li>
  <li>Voronoi Diagramì˜ ìµœì¢… ëª©í‘œ : ëª¨ë“  ì˜ì—­ ì•ˆì— ì„ì˜ì˜ ì§€ì ì€ ê·¸ ì•ˆì˜ Sample pointì™€ ìµœë‹¨ ê±°ë¦¬ë¥¼ ê°–ëŠ” ì˜ì—­ìœ¼ë¡œ ì •ì˜í•¨</li>
</ul>

<p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/22.png" alt="22" /></p>

<p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/23.png" alt="23" /></p>

<p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/24.png" alt="24" /></p>

<ul>
  <li>ê° sample pointì˜ classì— ë”°ë¼, ì „ì²´ ì˜ì—­ì˜ class ê²°ì •</li>
</ul>

<p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/25.png" alt="25" /></p>

<ul>
  <li>test Data ë“¤ì–´ì˜¤ë©´, ì´ë¥¼ í¬í•¨í•œ voronoi diagramì´ë©´ class ê²°ì •</li>
</ul>

<p><img src="/assets/img/2023-05-10-7.-k-Nearest-Neighbor.md/26.png" alt="26" /></p>


  </div><a class="u-url" href="/7.-k-Nearest-Neighbor" hidden></a>
</article>


      </div>
    </main><footer>
  <hr style="margin-left: 15px; color: #000 !important; background-color: #000 !important; opacity: 1 !important; width: 40px; height: .5px !important; margin-bottom: 2rem !important;">
  <div class="row m-0">
    <div class="col-12 col-md-3 col-sm-4 mb-4 mb-sm-0">
      <p>
        <a href="https://github.com/underthelights/underthelights.github.io" style="font-weight: 300">Kyuhwan Shim</a>
        <br>Up-to-date as of <span id="date">loading...</span></p>
      <i class="fas fa-location-dot mr-1"></i> Seoul is <img style="width: auto; height: 23px;" id="weather_icon">
      <span id="weather">Loading...</span>
    </div>
    <div class="col-12 col-md-9 col-sm-8">
      <p>
        <a style="font-weight: 300" href="https://linkedin.com/in/kyuhwan-shim"><i class="fab fa-linkedin" style="margin-right: 10.5px"></i>LinkedIn</a><br>
        <a style="font-weight: 300" href="https://fb.com/s.kyuhwn"><i class="fab fa-facebook" style="margin-right: 8px"></i>Facebook</a><br>
        <a style="font-weight: 300" href="https://www.instagram.com/s.kyuhwn"><i class="fab fa-instagram" style="margin-right: 10.5px"></i>Instagram</a><br>
        <a style="font-weight: 300" href="https://github.com/underthelights"><i class="fab fa-github" style="margin-right: 10.5px"></i>GitHub</a><br>
      </p>
    </div>
  </div>
</footer>

<script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.18.1/moment.min.js"></script>

<script src="/assets/js/weather.js"></script>
<script src="/assets/js/github_date.js"></script>
</body>

</html>
