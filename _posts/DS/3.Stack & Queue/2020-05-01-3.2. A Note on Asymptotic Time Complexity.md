---
title: "A Note on Asymptotic Time Complexity (Chapter 3.2)"
excerpt: "Chap 3."
slug: "3-2-asymptotic"

category: "data-structure"
lang: en
use_math: true
tags: ["CS", "data-structure"]
date: 2021-03-21T22:26:09-05:00
draft: false
---
## A Note on Asymptotic Time Complexity (Chapter 3.2)

- Time complexity of a program is given by the number of steps taken by the program to compute the function it was written for.

- The number of steps taken by the program depends on the size of input.
  - For example, suppose we search for a number in an integer array of size n, and the numbers are not sorted.
  - If the number we are looking for is not in the integer array, we need to check n integers before we conclude the number is not in the array.
  - Therefore, time complexity is expressed as a function of the input size.
  
  
  
- The number of steps taken by the program also depends on the input itself.
  - Consider the above example of searching for a number in an integer array.
  - If the number we are looking for is in the first position of the array, then the program will quickly finish.
  - Therefore, we typically consider worst-case time complexity, or sometimes average-case time complexity.

  
  
- We typically use "asymptotic" time complexity, instead of counting exact number of steps taken in the program
  - Asymptotic means "as the input grows to infinity".
  - So we are interested in how fast the running time will grow as the input size becomes larger.
  
  

### Big O

- To denote asymptotic time complexity, we typically use the big O notation.
  - Definition: We say f(n) = O(g(n)), iff there exist positive constants c and n0 such that f(n) ≤ c g(n) for all n, n ≥ n0.
  - Big-O indicates an upper bound on the asymptotic complexity.

<img width="276" alt="image-20211003152608732" src="https://user-images.githubusercontent.com/46957634/135751019-bdc184e5-fa37-4f23-a124-aa00454294e7.png">

- Expressing asymptotic time complexity using Big-O notation
  - O(1): constant
  - O(logn): logarithmic
  - O(n): linear
  - O(n2): quadratic
  - O(n3): cubic
  - O(2n): exponential
  
  
- In order for the statement f(n) = O(g(n)) to be informative, g(n) should be as small a function of n as one can come up with for which f(n) = O(g(n)).

<img width="343" alt="image-20211003152624239" src="https://user-images.githubusercontent.com/46957634/135751040-977f1073-dc95-4326-8cc3-645a8b63eb39.png">



### Limitation of asymptotic time complexity

- Asymptotic complexity does not count for constant factors. 
  - O(an + b) = O(n) when a and b are constants.
- Constant factors can dominate running time 
  - Especially when the input size is typically small 
  - e.g.) 1000n vs n2 when n < 1000

### Omega

$f(n) = \Omega(g(n))$

- iff there exist positive constants c and n0 such that f(n) ≥ c g(n) for all n, n ≥ n0.
- Omega indicates a lower bound on the asymptotic time complexity.
- In order for the statement f(n) = O(g(n)) to be informative, g(n) should be as large a function of n as one can come up with for which f(n) = Ω(g(n)).

### Theta

$f(n) = \Theta(g(n))$

- iff there exist positive constants c1, c2 and n0 such that $c1g(n) ≤ f(n) ≤ c2g(n) \forall n, n ≥ n0$
- Theta indicates a tight bound on the asymptotic time complexity.

<img width="276" alt="image-20211003152608732" src="https://user-images.githubusercontent.com/46957634/135751064-19831990-5df0-4cec-b148-8964a656da1d.png">

- If program P has complexity Θ(n) and program Q has complexity Θ(n2), we can assert that program P is faster than program Q for sufficiently large n.
- For comparing performance of two programs (or functions), we typically use the big-O notation with smallest g(n).
- number of step counts for different asymptotic functions.

<img width="366" alt="image-20211003152828640" src="https://user-images.githubusercontent.com/46957634/135751074-e382372f-e094-41d7-adad-ea2b9dbda745.png">

- plot of step count for different asymptotic functions.

<img width="279" alt="image-20211003152818439" src="https://user-images.githubusercontent.com/46957634/135751073-73a5070f-5506-4346-81c4-6949d4a0c2e1.png">

- Running time on a computer that executes 1 billion instructions per second.

<img width="384" alt="image-20211003152808228" src="https://user-images.githubusercontent.com/46957634/135751088-7ee93ad1-e917-41bc-b1dd-72a3f80325f3.png">
