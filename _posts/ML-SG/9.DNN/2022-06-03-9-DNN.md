---
title: "Deep Neural Net (Chapter 9)"
excerpt: "Chap9.DNN"
slug: "ML-9-DNN"
category: "ml"
lang: en
use_math: true
tags: ["ML", "AI", "Lecture"]
date: 2022-06-03T22:26:09-05:00
draft: false
---

# 9. DNN
Property 1: Goodfellow6-9

# Deep Learning

- A machine learning subfield. Exceptional performance in learning patterns.
- Deep learning algorithms attempt to learn (multiple levels of) representation by using a hierarchy of multiple layers.
- If you provide the system tons of information, it begins to understand it and respond in useful ways.

![Untitled](https://user-images.githubusercontent.com/46957634/188280841-5f543450-343f-428d-a710-2de87ec07d90.png)

- Manually designed features are often over-specified, incomplete and take a long time to design and validate
- Learned Features are easy to adapt, fast to learn
- Deep learning provides a very flexible, (almost?) universal, learnable
framework for representing world, visual and linguistic information.
- Can learn both unsupervised and supervised
- Effective end-to-end joint system learning
- Utilize large amounts of training data

## History

- In ~2012, deep learning (DL) started outperforming other machine learning (ML) techniques, first in speech and vision, then NLP

![Untitled_1](https://user-images.githubusercontent.com/46957634/188280850-84f61fd3-b882-4e05-88c2-f3a9726f65e9.png)
![Untitled_2](https://user-images.githubusercontent.com/46957634/188280851-27c1c196-b18a-48ad-8d1f-995ab74974d7.png)

## Structure

Ïñ¥ÎñªÍ≤å DLÏù¥ Ï¢ãÏùÄ ÏÑ±Îä•ÏùÑ ÎÇ¥ÎäîÍ∞Ä?

- Fat + Short vs. Thin + Tall Networks
- The same number of parameters

![Untitled_3](https://user-images.githubusercontent.com/46957634/188280852-f4b51bc9-82ea-40b6-8444-335edc605fd6.png)

- Deep ‚Üí Modularization
- 
![Untitled_4](https://user-images.githubusercontent.com/46957634/188280854-4800d400-c5a6-486d-9a1b-f5c9f0eac4ab.png)
![Untitled_5](https://user-images.githubusercontent.com/46957634/188280855-6388a472-0576-43ff-a35d-48ec1d93e0e8.png)
![Untitled_6](https://user-images.githubusercontent.com/46957634/188280857-b2c58c84-6ccd-40c2-bf71-c7c54072fa53.png)
![Untitled_7](https://user-images.githubusercontent.com/46957634/188280858-e8cb1992-3783-4534-ae1f-4aca21858335.png)
![Untitled_8](https://user-images.githubusercontent.com/46957634/188280860-ad51845e-23d1-433a-b6e2-8b4ce62bab6a.png)
![Untitled_9](https://user-images.githubusercontent.com/46957634/188280865-2800259e-5654-431e-a0f6-810f65f58103.png)
![Untitled_10](https://user-images.githubusercontent.com/46957634/188280869-d15d08ad-3e05-4ede-a963-a9f83b5b49e0.png)

- Before 2006, deeper usually does not imply better performance.

- [Geoffrey Hinton showed how to train deep network in 2006 [1]](https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985)
    - Learned layers one by one

- [Deep Neural Networks showed good classification performance with large image data set in 2012. [2]](https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985)
    - GPU
    - Big data
    - Better learning algorithms

![Untitled_11](https://user-images.githubusercontent.com/46957634/188280873-199a43e5-7947-49cb-a4e4-b95ea20e5443.png)

[http://www.gizmodo.com.au/2015/04/the-basic-recipe-for-machinelearning-explained-in-a-single-powerpoint-slide/](http://www.gizmodo.com.au/2015/04/the-basic-recipe-for-machinelearning-explained-in-a-single-powerpoint-slide/)

- Rectified Linear Unit (ReLU)
    - Fast to compute
    - Vanishing gradient problem

![Untitled_12](https://user-images.githubusercontent.com/46957634/188280876-10d270b6-6457-4cfe-aa5a-33ac75a73968.png)

- [[Xavier Glorot, AISTATS‚Äô11] [3]](https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985)
- [[Andrew L. Maas, ICML‚Äô13] [4]](https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985)
- [[Kaiming He, arXiv‚Äô15] [5]](https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985)

# Dropout

[Dropout [6]](https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985)

- Each time before computing the gradients
- Each neuron has $p \times 100 \%$ chance to be dropped
    - The structure of the network is changed
- Use the new network for training

![Untitled_13](https://user-images.githubusercontent.com/46957634/188280877-2dc86cb3-9b0d-4d4e-a023-9033c7feecfe.png)
![Untitled_14](https://user-images.githubusercontent.com/46957634/188280879-7b1bb0dc-9046-41c7-9b25-4a3a3181a9d7.png)


- Weights should be multiplied by (1-p) when testing

## Training stage

Assume dropout rate is 50% 

![Untitled_15](https://user-images.githubusercontent.com/46957634/188280880-ff0c4282-cd2d-4a25-8f52-c12f00c7b30f.png)

### Testing stage

No dropout

![Untitled_16](https://user-images.githubusercontent.com/46957634/188280882-0f356b1b-47ae-4161-ba6c-0bae951b40ef.png)

# Convolutional Neural Network

## Fully connected layer

- Example: 200x200 image * 40K hidden units ‚Üí ~2B parameters

![Slide Credit: Marc'Aurelio Ranzato](https://user-images.githubusercontent.com/46957634/188280884-b24fcebf-e58f-4fa8-91a0-f07fb0ae74f4.png)

Slide Credit: Marc'Aurelio Ranzato

- Waste of resources + we have not enough training samples
- Spatial correlation is local

## Locally Connected Layer

- Example: 200x200 image * 40K hidden units ‚Üí ~4M parameters (Filter size: 10x10)
Page 20- Spatial correlation is local

![Untitled_18](https://user-images.githubusercontent.com/46957634/188280885-abf3d04d-52d9-4cc0-8e77-652c6a175602.png)

- Waste of resources + we have not enough training samples
- Spatial correlation is local

![Untitled_19](https://user-images.githubusercontent.com/46957634/188280888-46729577-a232-4023-83ae-b674f374652f.png)

- Statistics is similar at different locations
    - Share the same parameters across
- different locations (weight sharing)
    - Convolutions with learned kernels
    

## Convolution operation

$F(m,n) = f * h = \Sigma_{l= -\frac w 2}^{\frac f 2}\Sigma_{k= -\frac w 2}^{\frac w 2} {f(m+k, n+l) *h(\frac w 2 -k, \frac w 2 -l)}$

![Untitled_20](https://user-images.githubusercontent.com/46957634/188280891-91050b9e-3257-4c55-8b39-17d9cfdb9f02.png)
![Untitled_21](https://user-images.githubusercontent.com/46957634/188280892-f7bb4b05-ff9c-4279-ab46-2a5d1fc9c858.png)


- If a feature is useful in some locations during training, detectors for that feature will be useful in all locations during testing

![Untitled_22](https://user-images.githubusercontent.com/46957634/188280893-984efb4c-2f50-4619-ada2-f6163419c454.png)

## Pooling

- By ‚Äúpooling‚Äù (e.g., taking max) filter responses at different locations, we gain robustness to the exact spatial location of features.

![Untitled](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/e67b7b1d-c185-4386-9709-7a1df8aa9300/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220903%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220903T170529Z&X-Amz-Expires=86400&X-Amz-Signature=ea14f0e42827df426e05d2d83b2b582cb021c2809728eb87c440796e4de8d8c1&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject)

![Untitled](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/e50a0769-e4bf-459b-a7d7-694d8349d6d5/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220903%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220903T170547Z&X-Amz-Expires=86400&X-Amz-Signature=086688091b424dd8949d23ca311338eb957bffd91cff034975057fbba1803b7c&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject)

![Untitled](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/2c85de26-0778-4864-b757-e7fe1d00e352/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220903%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220903T170601Z&X-Amz-Expires=86400&X-Amz-Signature=7c91f58dfc23593943ce40dd7b381a325b1ec8821b7e585b5787ade47df9584c&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject)

### Max-pooling

$h_i^n(r,c) = max_{\bar r \in N(r), \bar c \in N(c), } h_i^{n-1} (\bar r, \bar c)$

### Average-pooling

$h_i^n(r,c) = mean_{\bar r \in N(r), \bar c \in N(c), } h_i^{n-1} (\bar r, \bar c)$

### L2-pooling

$h_i^n(r,c) = \sqrt{\Sigma_{\bar r \in N(r), \bar c \in N(c), } h_i^{n-1} (\bar r, \bar c)}$

## Convolution kernel (filter) examples

![Untitled](9/Untitled_26.png)

- Examples of learned object parts from object categories
    
    ![Untitled](9/Untitled_27.png)
    

## LeNet-5 (1998)

[[7] Le-Net](https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985)

- Yann LeCun and his collaborators developed a really good recognizer for
handwritten digits by using backpropagation in a feedforward net with
    - Many hidden layers (at that time),
    - 3 convolution layer,
    - 2 subsampling (pooling) layer
    - 5*5 convolution kernels,
    - ~340,000 connections,
    - ~60,000 parameter
- Used for reading ~10% of the checks in North America
    
    ![Untitled](9/Untitled_28.png)
    

![Untitled](9/Untitled_29.png)

![Untitled](9/Untitled_30.png)

![Untitled](9/Untitled_31.png)

## Backpropagation in CNN

- Same color shares the same weight
- Compute the gradients as usual, and then modify the gradients so that they satisfy the constraints

![Untitled](9/Untitled_32.png)

![Untitled](9/Untitled_33.png)

- The 82 errors made by LeNet5
- Notice that most of the errors are cases that people find quite easy.
- The human error rate is probably 20 to 30 errors.

- LeNet uses knowledge about the invariances to design:
    - local connectivity
    - weight-sharing
    - Pooling
    - ~ 80 errors
- Using many different transformations of the input and other tricks (Ranzato2008)
    - ~ 40 errors
- Using carefully designed extra training data (Ciresan 2010)
    - For each training image, they produced many new training examples by applying many different transformations
    - ~ 35 errors

[Ciresan 2010][8]

![PyTorch implementation of LeNet-5 for MNIST, [https://github.com/radsn/LeNet5](https://github.com/radsn/LeNet5)](9/Untitled_34.png)

PyTorch implementation of LeNet-5 for MNIST, [https://github.com/radsn/LeNet5](https://github.com/radsn/LeNet5)

- The top printed digit is the right answer.
- The bottom two printed digits are the network‚Äôs best two guesses.
- The right answer is almost always in the top 2 guesses.
- With model averaging they can now get about 25 errors.

# From Handwritten Digits to 3-D objects

- Recognizing real objects in color photographs downloaded from the web is much more complicated than recognizing hand-written digits:
    - Hundred times as many classes (1000 vs 10)
    - Hundred times as many pixels (256* 256 color vs. 28* 28 gray)
    - Two dimensional image of three-dimensional scene
    - Multiple objects in each image
    - Cluttered background
- Will the same type of convolutional neural network work?

# The ILSVRC-2012 Competition on ImageNet

![Untitled](9/Untitled_35.png)

- [9] ImageNet
    - Over 15 million labeled high-resolution images
    - Roughly 22,000 categories
    - Collected from the web
    - Labeled by human using Amazon‚Äôs Mechanical Turk crowd-sourcing tool

- ImageNet Large-Scale Visual Recognition Challenge (ILSVRC)
    - Uses a subset of ImageNet
    - 1,000 categories
    - 1.2 million training images
    - 50,000 validation images
    - 150,000 test images
- The classification task:
    - Get the ‚Äúcorrect‚Äù class in your top 5 bets. There are 1000 classes.
- The localization task:
    - For each bet, put a box around the object. Your box must have at least 50%
    overlap with the correct box.
- Some of the best existing computer vision methods were tried on this dataset by leading computer vision groups from Oxford, INRIA, XRCE(XEROX), ‚Ä¶
    - Computer vision systems use complicated multi-stage systems
    - The early stages are typically hand-tuned by optimizing a few parameters

## Examples from the test set (with the network‚Äôs guesses)

![Untitled](9/Untitled_36.png)

Error rates on the ILSVRC-2012 competition

|  | classification | classification & localization |
| --- | --- | --- |
| UToronto
 | 16.4%  | 34.1% |
| UTokyo | 26.1% | 53.6% |
| Oxford University Computer Vision Group
 | 26.9% | 50.0% |
| INRIA + XRCE | 27.0% |  |
| UAmsterdam | 29.5% |  |
- UToronto (deep learning - Alex Krizhevsky, AlexNet)
- INRIA (French national research institute in CS) + XRCE (Xerox Research Center Europe)

# A CNN for ImageNet

AlexNet[10]

- Alex Krizhevsky (NIPS 2012) developed a very deep convolutional neural net of the type pioneered by Yann LeCun.

- 7 hidden layers not counting some max pooling layers
- The early layers are convolutional, the last two layers are fully connected
- The activation functions are
    - Rectified linear units in every hidden layer. These train much faster and are more expressive than sigmoid.
    - Normalization for better activation
- Use ‚Äúdropout‚Äù to regularize the weights in the fully connected layers
- 224*224 patches are taken from the 256*256 images (10 different versions) and leftright reflections are used to get more data
- Used all 10 different patches at test time

![Untitled](9/Untitled_37.png)

## More examples from AlexNet

![Untitled](9/Untitled_38.png)

## Hardware for AlexNet

- He uses a very efficient implementation of convolutional nets on two NvidiaGTX 580 Graphics Processor Units (over 1000 fast little cores)
    - GPUs are very good for matrix-matrix multiplies.
    - GPUs have very high bandwidth to memory.
    - This allows him to train the network in a week.
    - It also makes it quick to combine results from 10 patches at test time.
- We can spread a network over many cores if we can communicate the states fast enough.
- As cores get cheaper and datasets get bigger, big neural nets will improve faster than old-fashioned computer vision systems.

# Evolution of the DNN

- Network depths and the performance
- ILSVRC classification error (top-5 error)
    
    ![Untitled](9/Untitled_39.png)
    

# Fully Convolutional Networks

- Fully connected layer constrains the input image size
    
    ![Untitled](9/Untitled_40.png)
    
- Fully convolutional network structure has no constrains on the input image size
    
    ![Untitled](9/Untitled_41.png)
    

# Machine Learning, Deep Learning, Data Mining, Big data

## Big Data

- Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞Ïùò ÌÅ¨Í∏∞ Î≤îÏ£ºÎ•ºÎÑòÏñ¥ÏÑúÎäî Í∑úÎ™®(2010~)
- Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ Ïù¥Ïäà Í≥µÏú†
- ÎåÄÏö©Îüâ Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÇ∞Ï†ÄÏû•/Ï≤òÎ¶¨ Î∞©Î≤ï ÌïÑÏöî

## Machine Learning

- Îç∞Ïù¥ÌÑ∞Ïùò ÏÜçÏÑ±ÏùÑ ÏùºÎ∞òÏ†ÅÏúºÎ°ú Î∂ÑÏÑùÌïòÎäî Î∞©Î≤ï, Ï£ºÎ°ú Î∂ÑÎ•ò/ÌöåÍ∑Ä ÏûëÏóÖÏóê ÏÇ¨Ïö©Îê®(1950~)
- ÏßÄÎèÑÌïôÏäµ/ÎπÑÏßÄÎèÑÌïôÏäµ/Íµ∞ÏßëÌôî
- Ï≤¥Ïä§ Í≤åÏûÑÏúºÎ°úÎ∂ÄÌÑ∞ Î∞úÏ†Ñ

## Deep learning

- Ïã¨Ï∏µ Ïù∏Í≥µÏã†Í≤ΩÎßù Í∏∞Ïà†ÏùÑ ÏÇ¨Ïö©ÌïòÎäî Í∏∞Í≥ÑÌïôÏäµ Î∞©Î≤ï(2010~)
- Í∏∞Ï°¥ Í∏∞Í≥ÑÌïôÏäµ Î∞©Î≤ïÏùò ÏÑ±Îä•ÏùÑ Îõ∞Ïñ¥ ÎÑòÏùå

## Data Mining

- Îç∞Ïù¥ÌÑ∞Ïóê ÎÇ¥Ïû¨Îêú ÏÜçÏÑ±ÏùÑ Î∂ÑÏÑù (1930~)
- Í∏∞Í≥ÑÌïôÏäµÍ≥º Ïú†ÏÇ¨ÌïòÎÇò Îç∞Ïù¥ÌÑ∞ Í∞ÑÏùò Í∑úÏπôÏùÑ Î∂ÑÏÑùÌïòÎäî Ï∏°Î©¥ÏúºÎ°ú Ï∞®Î≥ÑÌôî

## Some history

- Frank Rosenblatt, Perceptron (1957, 1962): Early description and engineering of single-layer and multilayer artificial neural networks.
    
    ![Untitled](9/Untitled_42.png)
    
- Kasparov vs Deep Blue, 1997
    
    ![Untitled](9/Untitled_43.png)
    
- Lee Sedol vs AlphaGo, 2016
    
    ![Untitled](9/Untitled_44.png)
    

### timelines

- 1943: Neural networks
- 1957-62: Perceptron
- 1970-86: Backpropagation, RBM, RNN
- 1979-98: CNN, MNIST, LSTM, Bidirectional RNN
- 2006: ‚ÄúDeep Learning‚Äù, DBN‚Ä¢ 2009: ImageNet + AlexNet
- 2014: GANs
- 2016-17: AlphaGo, AlphaZero
- Turing Award given for:
    - ‚ÄúThe conceptual and engineering breakthroughs that have made deep neural
    networks a critical component of computing.‚Äù
    ‚Ä¢ Yann LeCun
    ‚Ä¢ Geoffrey Hinton
    ‚Ä¢ Yoshua Bengio

## Limitations of Deep Learning

![Untitled](9/Untitled_45.png)

- Prediction from Rodney Brooks:
‚ÄúBy 2020, the popular press starts having stories that the era of Deep Learning is over.‚Äù

- 2019 is the year it became cool to say that ‚Äúdeep learning‚Äù has limitations.
- Books, articles, lectures, debates, videos were released that learning-based methods cannot do commonsense reasoning.

## Statics of acceptance rate NeurIPS

![Untitled](9/Untitled_46.png)

## Deep Learning Framework/Toolkits

![Untitled](9/Untitled_47.png)

## AlexNet

https://sushscience.wordpress.com/2016/12/04/understanding-alexnet/

![Untitled](9/Untitled_48.png)

---

[1] Geoffrey Hinton showed how to train deep network in 2006 

[2] Deep Neural Networks showed good classification performance with large image data set in 2012.

[[3] [Xavier Glorot, AISTATS‚Äô11]](https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985)

Deep Sparse Rectifier Neural Networks. ***Xavier Glorot,¬†Antoine Bordes,¬†Yoshua Bengio***
¬†*Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics.*¬†PMLR 15:315-323,¬†2011.

- [https://proceedings.mlr.press/v15/glorot11a.html](https://proceedings.mlr.press/v15/glorot11a.html)

[[4] [Andrew L. Maas, ICML‚Äô13]](https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985) 

Rectifier nonlinearities improve neural network acoustic models (2013) by Andrew L. Maas , Awni Y. Hannun , Andrew Y. Ng

[https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf](https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf)

[[5] [Kaiming He, arXiv‚Äô15]](https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985) 

Deep Residual Learning for Image Recognitionüìπ
by Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385)

[[6] Dropout: A Simple Way to Prevent Neural Networks from Overfitting](https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985)

***Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov***; 15(56):1929‚àí1958, 2014.

[6.2. DropOut](https://www.notion.so/6-2-DropOut-7f9244899e884b27969f212af344b6a1)

[Dropout: A simple way to prevent neural networks from overfitting (2014), N. Srivastava et al. [pdf]](https://www.notion.so/Dropout-A-simple-way-to-prevent-neural-networks-from-overfitting-2014-N-Srivastava-et-al-pdf-b70dbe733db749bfbff250abeb9813e4)

[https://jmlr.org/papers/v15/srivastava14a.html](https://jmlr.org/papers/v15/srivastava14a.html)

[[7] Le-Net](https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985)

[http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)

[5.1. **LeNet**](https://www.notion.so/5-1-LeNet-8a448781423b4a3591b77dd91d76a272)

[8] [Ciresan 2010]

[9] ImageNet

[ImageNet](https://www.notion.so/ImageNet-67d9a42cba374a83afb7836c48e304f6)

ImageNet: A large-scale hierarchical image database

by Jia Deng; Wei Dong; Richard Socher; Li-Jia Li; Kai Li; Li Fei-Fei