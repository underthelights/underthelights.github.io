---
title: "ML SG Repackage (Chapter 7-13)"
excerpt: "ML repkg"
slug: "ML-SG-REPKG"
category: "ml"
lang: en
use_math: true
tags: ["ML", "AI", "Lecture"]
date: 2022-06-15T22:26:09-05:00
draft: false
---


# [Final Repkg. for ML]

# 7. kNN

[7. k-Nearest Neighbor](https://www.notion.so/7-k-Nearest-Neighbor-abad63e2757e4de39af29914c4c63e82)

- **kNN = Instance based learning**
    
    ì£¼ì–´ì§„ test sample Xì— ëŒ€í•˜ì—¬, kNN samples (xn1, yn1) â€¦ (xnk, ynk)ë¥¼ ìœ„ì¹˜ì‹œì¼œ majority class label yn1, .. ynkë¥¼ xtì— assigní•œë‹¤.
    
- **kNN pros and cons**
    - pros :
        - training is very fast : feature extraction and save
        - learn complex target fn
        - doesnâ€™t lose info
    - cons :
        - slow at test  â†’ not goot
        - requires large storage
        - not robust against irrevalent attributes, outliers
- **Distance Metrics**
    - kNN - test ì‹œì  ) dataì™€ Nearí•œì§€ distance ê³„ì‚°
    - distance : ëª¨ë“  Classification , regressionì—ì„œ ì¤‘ìš”
        - ë‹¨ Nominal dataë‹¤ë£¨ëŠ” DTì—ì„œëŠ” ë¶ˆí•„ìš”
        - similiarityì™€ ë°˜ë¹„ë¡€
    - Euclidean distance : $\sqrt{\Sigma_{d=1}^{D} |x_{td} - x_{nd}|^2}$
    - Manhattan distance : ${\Sigma_{d=1}^{D} |x_{td} - x_{nd}|}$
    - $L^n$-norm : $\sqrt{\Sigma_{d=1}^{D} |x_{td} - x_{nd}|^n}$
    
    - When we say â€˜nearestâ€™, it depends on the distance metric :
        - Euclidean distance : $\sqrt{\Sigma_{d=1}^{D} |x_{td} - x_{nd}|^2}$
        - Manhattan distance : ${\Sigma_{d=1}^{D} |x_{td} - x_{nd}|}$
        - $L^n$-norm : $\sqrt{\Sigma_{d=1}^{D} |x_{td} - x_{nd}|^n}$
        
    - Each dimension can be differently **scaled**
        - Each dimension may have different impact
        - May **bias** the performance of the classifier $\sqrt{\Sigma_{d=1}^{D} w_d|x_{td} - x_{nd}|^2}$
            - ë™ì¼í•œ ê¸°ì¤€ ì¸¡ì • X â†’ performance bias ë°œìƒ ê°€ëŠ¥
            - weightë¥¼ íŠ¹ì • featureì— ë„£ì–´ ê±°ë¦¬ì˜ ìƒëŒ€ì ì¸ í¬ê¸°ë¥¼ featureì— ë”°ë¼ì„œ ë„£ëŠ”ë‹¤
- **VDM**
    
    provide d measurements for nominal attributes
    
- **Problem from Euclidean distance**
    1. High dim data - curse of dimensionality
        - ë„ˆë¬´ ë§ì´ feature, attrib ì¦ê°€ì‹œí‚¬ ê²½ìš° dimì´ ë„ˆë¬´ ë§ì´ ì¦ê°€í•´ ì°¨ì›ì˜ì €ì£¼
        - sampleë¡œë¶€í„° available info ê°€ ë§ê³  ì •í™•í•˜ë‹¤ë©´ dim ë†’ì•„ë„ ê´œì°®ìŒ
    2. ë³´í†µ sparseí•˜ê³  densityë¥¼ shrinkí•˜ì—¬ ì ìš©í•œë‹¤.
    3. ê³¼ì—° dê°€ ë™ì¼í•˜ë‹¤ê³  data featureë¥¼ ì˜ ë‚˜íƒ€ë‚¼ê¹Œ?
        - MSB, LSB ë“± bit ì—°ì‚°ìœ¼ë¡œë¶€í„° ì˜ í‘œí˜„ì´ ì•ˆë ìˆ˜ë„ ìˆìŒ
        - Hamming d.
- **Behavior of limit**
    
    $\lim _{n \rightarrow \infty} \leq 2 \epsilon ^*$
    
    pf) goodnote ì°¸ê³ 
    
- **Standardization**
    
    z = x - mu / sigma
    
- **how to choose k**
    - k is too small â†’ sensitive to noise points
    - k is too big â†’ neighborhood may include pts from other classes
        - smoother when k get bigger
    - ë³´í†µ $k = \sqrt N$
    - $n \rightarrow \infty$, k gets larger â†’ good performance as good as bayes classifier
- **Cross Validation !!!**
    - N fold cross validation â†’ k to minimize cross valid error
    
    overfittingì— ì˜í•´ - train errorë¥¼ ì¤„ì´ëŠ” ê²ƒì´ ë¬´ì‘ì • ì¢‹ì§€ëŠ” ì•Šë‹¤
    
- **Condensing!!!**
    - [Aim] reduce the number of training samples
    - Decision boundary consistent : same with entire training set
        - min. consistent set : smallest subset of samples
    
    1) init subset with single ex. 
    â†’ 2) nearest neighbor ìƒì„±, epsilonë‚˜ì˜¤ëŠ” incorrected samples ì„ íƒ 
    â†’ 3) 2)ë°˜ë³µ Until no transfers or subset is full â†’ result êµ¬í•˜ê¸°
    
- **Voronoi Diagram**
    - Voronoi Diagram : div space into such cells : êµ¬íšìœ¼ë¡œ ë‚˜ëˆ„ê³  boundary ì˜í–¥ì—†ëŠ” sample del
    - Delaunary triagulation ìƒì„± â†’ circumcircle center pt ë¼ë¦¬ ì—°ê²° : 
    ê° sample pt classì— ë”°ë¼ ì „ì²´ ì˜ì—­ Class ê²°ì •
        - Delaunary triagulation : ì‚¼ê°í˜•ì˜ ì„¸ ì ì— ì™¸ì ‘í•˜ëŠ” ì‚¼ê°í˜•, ê°ë„ ìµœëŒ€í™”
        - not unique
    - 

# **8. ANN**

[8. ANN](https://www.notion.so/8-ANN-2866fb8a17b645a1af86f8a713f28c3d)

- **Differences with**
    - Similar : SVMì²˜ëŸ¼ high dimension mappingê³¼ ìœ ì‚¬í•œ input layer to hidden layer
        - ì›ë˜ feature spaceì—ì„œëŠ” not linearly separable â†’ phi fn(high dim) ìœ¼ë¡œ sol
    
- **Bitwise Calc.**
    
    perceptron : AND, ORì—°ì‚° ê°€ëŠ¥í•˜ë‚˜ XOR ë¶ˆê°€ëŠ¥ 
    
    - sol: XORì´ nonlinearí•´ì„œ ìƒê¸´ ë¬¸ì œ : 2 Decision boundary
- **ANN Training**
    - input - hidden - output : hidden layer ìˆ˜ì— ë”°ë¼ ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°ê°€ ì¢Œìš°ë˜ë©° linearly nonsolvable ë¬¸ì œë„ í•´ê²°í•´ë‚¼ ìˆ˜ ìˆë‹¤
    - 1) decide input /output / hidden layer node number 
    â†’ 2) find weight using training alg (backpropagation)
    - #class = #node
- **Backpropagation**
    - (ë“±ì¥ë°°ê²½) NN-SVM-DNNì—ì„œ SVMì´ ë§ì´ ì“°ì´ëŠ” ê²½ìš°ì˜€ìŒ. NNì—ì„œ overfitting / XORë¬¸ì œ
    - (Idea) Weight wë¥¼ Error ê°ì†Œí•˜ëŠ” ë°©í–¥ìœ¼ë¡œ Update - between prediction vs ground truth val
    - (prob. similar to perceptron) stuck in local minima, iteratively get w, many w to get y
    - chain rule
- **Vanishing Gradient Problem**
    
    errorë“¤ì´ backpropagateí•˜ë©´ gradientê°€ vanishí•˜ëŠ” í˜„ìƒ : layerì—ì„œ ì†Œìˆ˜ì ì´ ê³±í•´ì§ˆìˆ˜ë¡ 0ìœ¼ë¡œ ìˆ˜ë ´í•˜ê¸° ë•Œë¬¸ì´ë‹¤. w = w - eta dE/du
    
    - sol : requires lots of data
    - nonlinear ReLU
    - Layerwise learning : ì¶©ë¶„íˆ í•™ìŠµë˜ë©´ ë„˜ì–´ê°
- **Overfitting**
    - Only get good result for train data only
    
    get stuck in local minima 
    
    - solution : randomly set initial val +many data + much computation powerâ†’ train many times â†’ avg ì¶”ì¶œ
    
    good model check
    
    - solution : train data, test data ë³€í™”ì‹œí‚¤ë©° stable resultë¥¼ ë³´ì´ëŠ”ì§€ í™•ì¸í•œë‹¤

# 9. DNN

[9. DNN](https://www.notion.so/9-DNN-4bd3fcaa9c98476dbe325f886d729985)

- **Why is better than traditional ML**
    - SVM) Manual, Human supervised, div and conquer
        - ê¸°ì¡´ì— humanì´ feature extractioní•œ í›„ classificationí•¨.
        - SVMì—ì„œëŠ” Hand-crafted phi fnì„ í™œìš©í•´ì„œ algì—ì„œ Patternì´ ë” ì˜ ë³´ì´ë„ë¡ ìˆ˜ì •í–ˆë‹¤
    - DL) Automatical, end-to-end NN
        - end-to-end joint system : NNì´ë¼ëŠ” hierarchical structureë¡œ feature extract + classification ê³¼ì • ìˆ˜í–‰
            - â†’ dataë¥¼ ì§€ì†ì ìœ¼ë¡œ ë¶„ë¥˜ : ìì²´ì ìœ¼ë¡œ ìë™ì ìœ¼ë¡œ ë°°ìš°ê³  ì§€ëŠ¥ì ì¸ ê²°ì • ìˆ˜í–‰
        - modularization : automatically learned from data (each classes)
- **DNN consist**
    - input layer + multiple hidden l + output layer
- **(CNN) Layers : FC Layer, Locally connected layer**
    
    corelation êµ¬í•˜ëŠ” ì‘ì—… â†’ ì¡°í•©ì„ ë‹¤ìŒ layerë¡œ ì „ë‹¬í•œë‹¤.
    
    - FC : globally corelated - rsrc waste, too much calc., not enough data to train pm
    - LC : ì¼ì • convolutionë‚´ node (different locations-convolutions with learned kernel)
        - convolution : íŠ¹ì • Window size filter
- **(CNN) Conv. operations**
    - Conv A * B = B * A
    - cross-corelation : A . B â‰  B . A
    - auto-correlation : ìê¸° ìì‹ ê³¼ ë™ì¼
- **(CNN) Pooling**
    
    filter responses at different location â†’ robustnest to spatial location of filters
    
    - max, avg, l2 pooling
- **(CNN) size of feature map ê³„ì‚°**
    
    
- **tasks**
    - Classification : exact class ë¶„ë¥˜
    - Localization : obj ì£¼ë³€ì— boxë¥¼ ë‘ê³  ì •ë‹µê³¼ ì ì–´ë„ 50%ì´ìƒ ê²¹ì³ì•¼ í•¨
    - Obj Detection : nê°œì˜ objì— ëª¨ë‘ boundary box ì²˜ë¦¬
    
- **Alexnet**
    - act. fn. : ReLU in Hidden layers â†’ faster, expressive than sigmoid
    - ten different 224*224 patches from from 256*256 img
    - dropout to reg. weight in FC layers
    - padding
- **FC Layer**
    
    has no constrains the input img size (ìƒê´€ ì—†ìŒ)
    
- **DNN Evolution**
    
    NN - Perceptron - Backporpagatino ,RNN, RBM - CNN, MNIST, LSTM, BRNN - DBN - GAN - AlphaGo
    
    - data labeled
    - obj detection focused
    - GPU
        - good for mat*mat multiplies + high bandwidth
    - shallower
- **Backgrounds**
    - HW (GPU) + Data (Big data) + Alg (learning Alg)
    - limit : cannot do commonsense reasoning - ìƒì‹, ìœ¤ë¦¬ì˜ Lack

# 10. DNN2

[10. DNN 2](https://www.notion.so/10-DNN-2-c5c97bb69d724e25bb655b70f34d2575)

- **Data Processing**
    
    
    In practice, you may also see PCA and Whitening of the data
    
    PCA : dimensionality reduction, clustering (unsupervised)
    
    - decorrelated data
        - (data has diagonal covariance matrix)
        - axisë°©í–¥ìœ¼ë¡œ í‰í–‰ : with x1 only (1dim)
        - from 2dim â†’ 1dim compression (data info loss)
    - whitened data
        - (covariance matrix is the identity matrix)
            
            $\Sigma =$
            
        - acc ë³€í™”í–ˆì„ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ performance ì²´í¬
- **Weight Init.**
    
    
    â€œXavier initializationâ€ [Glorot et al., 2010]
    
    ```python
    W = np.random.randn(fanin, fanout) / np.sqrt(fanin)
    ```
    
    - Reasonable initialization. (Mathematical derivation assumes linear activations) with tanh fn
    - í˜„ì¬ layer nodeì˜ sqrtë¡œ init
    - but when using the ReLU nonlinearity it breaks. (0ì— ì ‘ê·¼)
    
    He et al., 2015 (note additional /2)
    
    - errorê°€ ë” ì˜ ê°ì†Œë¨ì„ í™•ì¸í•  ìˆ˜ ìˆìŒ
    
    ```python
    W = np.random.randn(fanin, fanout) / np.sqrt(fanin/2)
    ```
    
- **Batch Normalization**
    
    
    - To make each dimension unit gaussian, apply:
        - $\hat x^{(k)} = \frac{x^{(k)} - E[x^{(k)}]}{\sqrt{Var[x^{(k)}]}}$
            - this is a vanilla differentiable function...
    - dimension ë‹¨ìœ„ normalilze
    
    1. compute the empirical mean and variance independently for each dimension.
        
        ![Untitled](Final/10/Untitled.png)
        
    2. Normalize
        - $\hat x^{(k)} = \frac{x^{(k)} - E[x^{(k)}]}{\sqrt{Var[x^{(k)}]}}$
    - Usually inserted after Fully Connected or Convolutional layers, and before **nonlinearity.**
    
    ![Untitled](Final/10/Untitled_1.png)
    
    - Normalize:
        - $\hat x^{(k)} = \frac{x^{(k)} - E[x^{(k)}]}{\sqrt{Var[x^{(k)}]}}$
        - $\hat x \sqrt{Var} + E[x] = X$
        - $\gamma = \sqrt{Var} , \beta = E[x]$
        - $\hat x$ : normalized data, X : original data
    - And then allow the network to squash the range if it wants to:
        - $\hat y^{(k)} = \gamma^{(k)} \hat x^{(k)}+\beta^{(k)}$
    - Note, the network can learn:to recover the identity mapping.
        - $\gamma^{(k)} = \sqrt{Var[x^{(k)}]}$ (stretch)
        - $\beta^{(k)} = E[x^{(k)}]$ (ì´ë™)
        
    - $X \rightarrow \hat X$ : normalize : $\gamma, \beta$ë¡œ scalingëœ y value
- **Regularization**
    
    
    $$
    L = \frac 1 N \Sigma_{i=1}^{N} \Sigma_{j\neq y_i}{\max(0, f(x_i);W)_j - f(x_i);W)_{y_i} +1} + \lambda R(W)
    $$
    
    - Loss Fn : $\frac 1 N \Sigma_{i=1}^{N} \Sigma_{j\neq y_i}{\max(0, f(x_i);W)_j - f(x_i);W)_{y_i} +1}$
    - Lambda weight term $+ \lambda R(W)$
    
    ![Untitled](Final/10/Untitled_2.png)
    
    - In common use:
        
        ![Untitled](Final/10/Untitled_3.png)
        
- **Dropout**
    - (ë°°ê²½) deep NN ì¼ìˆ˜ë¡ íŠ¹ì • nodeê°€ í•™ìŠµ ì‹œ dropped case ë°œìƒ
    - (train) assume dropout rate p â†’ (test) no dropout
- **regularization common pattern**
    
    
    - Cross Entropy Loss : $-\Sigma y_i \lim P_i$
        - yi : the answer
        - Pi : prediction
    - Training: Add some kind of randomness
        - randomness - regularize
        - $y = f_W (x,z)$
    - Testing: Average out randomness (sometimes approximate)
        - $y = f(x) = E_z[f(x,z)] = \int p(z)f(x,z)dz$
        - iterationë³„ ì—¬ëŸ¬ mu, sigma â†’ averageë¥¼ êµ¬í•˜ì—¬ testì‹œì ì— ì ìš©í•œë‹¤
        - BNë„ regularizationì‘ì—…
    - Example:BatchNormalization
        - Training:Normalize using stats from random mini batches
        - Testing:Use fixed stats to normalize

# 11. Ensemble learning

[11. **Ensemble Learning**](https://www.notion.so/11-Ensemble-Learning-afd95182fd9c4803b961642026442403)

- Ensemble Learning
    1. 
- Generate Ensembles
    
    
    - Data Manipulation
        
        1. Train setì— ë³€í™”
        
        Supervised learningì—ì„œ train setì— ëŒ€í•´ train ë˜ì–´ ì–»ì–´ì§„ model
        
        - ë‹¤ë¥¸ train setì„ ì‚¬ìš©í•˜ë©´ -> ë‹¤ë¥¸ model : ë¶„ë¥˜ ì„±ëŠ¥ì´ ë‹¤ë¦„
        - it changes the training set in order to obtain different models
    - Modeling process manipulation
        
        2. algorihtmì— ë³€í™”
        
        - model process manipulation : algorithmì˜ ë³€í™”
        - parameterë§Œ ë³€í™”í•˜ëŠ” ê²½ìš°ë„ ìˆê³ , classifier ìì²´ë¥¼ ë³€ê²½í• ìˆ˜ë„ ìˆìŒ, algorithm ìì²´ë¥¼ ë³€í™”ì‹œí‚¬ìˆ˜ë„ ìˆê³ 
        - â†’ ë‹¤ì–‘í•œ model (f1 _ /// fk)
        - it changes the induction algorithm, the parameter set or the model in order to obtain different models
- **Ensemble learning via negative correlation learning:**
    - Generating sequentially new predictors **negatively correlated** with the existing ones
        - í˜„ì¬ classifierí•˜ê³  negative corelationê°–ëŠ” classifierë¥¼ í•™ìŠµí•˜ì—¬ ìœµí•©í•œë‹¤
- Bagging
    - Averaging the prediction over a collection of predictors generated from **bootstrap samples** (both classification and regression)
        
        bootstrap sample :trian dataìˆìœ¼ë©´ subset sampling
        
        - ê°ê° samplingìœ¼ë¡œë¶€í„° classifier í•™ìŠµ
            
            Randomí•˜ê²Œ samplingí•˜ë©° ë‹¤ì–‘í•œ model
            
    
    - Training
        - Given a set D of d tuples, at each iteration i, a training set $D_i$ of $d$ tuples is sampled with replacement from D (i.e. bootstrap)
            - bootstrap ë°©ë²• : sampling with replacement - ì „ì²´ datasetìœ¼ë¡œë¶€í„° samplingí•˜ì—¬ modelingí•˜ê³  ë‹¤ì‹œ ë³µì›
            - ê°ê°ì˜ data subsetì— ëŒ€í•˜ì—¬ modelì„ ë§Œë“¬
    
    average, Sum ì€ ê°™ì€ ë°©ì‹ : sumì—ì„œ classifier numberë§Œí¼ ë‚˜ëˆ ì£¼ë©´ average value
    
    - bootstrapping = original dataë¡œë¶€í„° sampling
    - aggregating = ê·¸ê²ƒë“¤ë¡œë¶€í„° ê°ê°ì˜ classifierë¥¼ ë§Œë“¤ì–´ ë³‘í•©í•˜ëŠ” ë°©ë²•
    - Classification: classify an unknown sample X
        - Each classifier $M_i$ returns its class prediction
        - The bagged classifier $M^*$ counts the votes and assigns the class with the most votes to X
            - ê° classifierê°€ sampleì— ëŒ€í•œ class ì˜ˆì¸¡ê°’ì„ ê³„ì‚°í•˜ê³ , ê·¸ë¦¬ê³  ìµœì¢… íŒë‹¨ì€ voting / sum/ ë“± ì—¬ëŸ¬ ë°©ë²•ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.
    - Prediction:
        - can be applied to the prediction of continuous values by taking the average value of each prediction for a given test tuple
        
    
    - Accuracy
        - Often significantly better than a single classifier derived from
            
            significantly better : 5 ~ 10% ìƒìŠ¹
            
            - ë¬¼ë¡  modelì„ ì—¬ëŸ¬ë²ˆ ì“°ê³  ì—°ì‚°ëŸ‰ì€ ê·¸ë§Œí¼ ì¦ê°€
            - test stage : Test sampleì—ì„œëŠ” modelë“¤ ë‹¤ ìœ ì§€í•´ì„œ ê·¸ë§Œí¼ ë¶„ë¥˜ ì‘ì—… ìˆ˜í–‰ í›„ ìœµí•©
            
            Train + test stage ì—°ì‚°ëŸ‰ ì¦ê°€
            
        - For noisy data: not considerably worse, more robust
            - noisy data : robustí•˜ê²Œ ë¨ (boost sampling : Noisy dataê°€ ë¹ ì§„ í˜•íƒœë¡œ í•™ìŠµ)
        - Proved improved accuracy in prediction
    - Requirement: need unstable classifier types
        - Unstablemeansasmallchangetothetrainingdatamayleadtomajor decision changes
        - requirement : unstable classifier
        
        Unstable : train dataë¥¼ ì¡°ê¸ˆ ë°”ê¿€ ê²½ìš° model decisionì´ í¬ê²Œ ë°”ë€ŒëŠ” modelì„ ì˜ë¯¸í•¨
        
        (Remind) Modelì´ ë°”ë€ train dataì— ëŒ€í•´ì„œ diverseí•œ error = varianceê°€ ì»¤ì•¼ í•œë‹¤.
        
        - baggingì˜ ê´€ì ì—ì„œëŠ” var í°ê²Œ ì¢‹ë‹¤ (ì¼ë°˜ì ìœ¼ë¡œëŠ” ë³„ë¡œ ì•ˆ ì¢‹ë‹¤)
    
    - Stability in Training
        - Training: construct classifier from
        - Stability: small changes on results in small changes on
            
            Training : fë¥¼ dë¡œë¶€í„° í˜•ì„±
            
        - Decision trees are a typical unstable classifier
- Boosting
    - Weighted vote with a collection of classifiers that were trained sequentially from training sets given priority to instances **wrongly classified**
        
        Boosting : ì—¬ëŸ¬ ë‹¨ê³„ë¥¼ ê±°ì³ classifier í•™ìŠµ
        
        - ì´ì „ ë‹¨ê³„ì˜ classifierì˜ ì˜¤ë‹µì— ì´ˆì ì„ ë§ì¶˜ë‹¤.
        
        ì˜¤ë¥˜ê°€ ë‚˜ì˜¤ëŠ” dataë“¤ì„ ëª¨ì•„ ë‹¤ìŒ stageì—ì„œ ì´ˆì ì„ ë§ì¶”ì–´ í•™ìŠµí•˜ì—¬ ìœµí•©í•œë‹¤
        
    
    - Incrementally create models selectively using training examples based on some distribution.
        - Incrementallyí•˜ê²Œ sampleì´ subsetìœ¼ë¡œ selectionëœ í™•ë¥ ê°’ì„ ê°€ì§€ê³  ìˆìŒ
    - How boosting works?
        - Weights are assigned to each training example
        - A series of k classifiers is iteratively learned
        - After a classifier $M_i$  is learned, the weights are updated to allow the subsequent classifier, $M_i +1$, to pay more attention to the training examples that were misclassified by
        - The final $M^*$ combines the votes of each individual classifier, where the weight of each classifier's vote is a function of its accuracy ğ’Š
    - ê° sampleë“¤ì´ weightë¥¼ ê°€ì§€ê³  ìˆìŒ.
    
    ê·¸ë¦¬ê³  ìš°ë¦¬ëŠ” kê°œì˜ classifierë¥¼ í•™ìŠµí•  ê²ƒ
    
    ê·¸ëŸ°ë° M_iê°€ í•™ìŠµ ëœ ë‹¤ìŒ, classifierê°€ í•™ìŠµëœ ì´í›„ì—ëŠ”
    
    weightì„ updateí•˜ëŠ”ë° ì• ë‹¨ê³„ì—ì„œ í•™ìŠµëœ modelë“¤ì´ misclassified ì— ë” ì£¼ì˜ë¥¼ ê¸°ìš¸ì¸ë‹¤ (weightë¥¼ ì˜¬ë¦°ë‹¤)
    
    - > higher chance to be selected
    
    ì¦‰ misclassified sampleë“¤ì´ ì ì  ê·¸ ìª½ìœ¼ë¡œ selectë˜ë©´ì„œ hard sampleë“¤ì´ ì ì  ì¶”ê°€ë˜ì–´ ë’¤ìª½ classifier í•™ìŠµ
    
    1~kê°œ classifierë¥¼ ì¡°í•©í•˜ì—¬ m*
    
    - weighted combination : weightëŠ” accuracyì— ë¹„ë¡€
    - boosting ê¸°ë³¸ ì•„ì´ë””ì–´ : disagreement, hard sample
    
    Hard sampleì— ì´ˆì  ë§ì¶”ëŠ” ë°©ë²• : classifier 1ë²ˆì„ ë§Œë“¤ê³  misclassifiedì— ëŒ€í•´ì„œ classifier 2ë²ˆì„ ë§Œë“¤ê³  m1, m2ê°€ ë‹¤ë¥¸ ê²°ì •ì„ ë‚´ë¦¬ëŠ” sampleì— ëŒ€í•´ì„œ classifier 3ë²ˆì„ ë§Œë“¤ì–´ test sampleì´ ë“¤ì–´ì˜¤ë©´ m1, m2ë¥¼ ëŒë ¤ ìµœì¢… ê²°ê³¼ë¡œ ì‚¬ìš©í•˜ê³  ë‘ ë¶„ë¥˜ê¸° ê²°ê³¼ê°€ ë‹¤ë¥´ë©´ m3ë¥¼ í™œìš©í•˜ì—¬ ê²°ê³¼ ë„ì¶œ
    
- Boosting - Adaboost
    
    
    - Using Different Data Distribution
        - Start with uniform weighting
        - misclassified sampleì˜ weight ì¦ê°€
        - well classified sampleì— ëŒ€í•´ì„œëŠ” weight ê°ì†Œ
        - During each step of learning
            - Increase weights of the examples which are not correctly learned by the weak learner
            - Decrease weights of the examples which are correctly learned by the weak learner
    - Idea
        - Focus on difficult examples which are not correctly classified in the previous steps
        - difficult exampleì— ë” ì£¼ì˜ë¥¼ ê¸°ìš¸ì¸ ì¼€ì´ìŠ¤
    
    - Weighted Voting
        - Construct strong classifier by weighted voting of the weak classifiers
        - 
        - strong classifier ë§Œë“¤ ë•Œ weak classifier ì— weightë¥¼ ì£¼ê³  weighted voting / weighted sum ë“± ì¼ë°˜ì ì¸ ensemble ë°©ë²• ì ìš©
        - weak classifierë¥¼ ë§ì´ ì²¨ê°€í•˜ì—¬ combined classifierì˜ accuracy ì¦ê°€ (strong classifier/learner)
    - Idea
        - Better weak classifier gets a larger weight
        - Iteratively add weak classifiers
            - Increase accuracy of the combined classifier through minimization of a cost function Ensemble Learning Adaboost Introduction to Machine Learning Page 17
- Adaboost vs Boosting
    
    
    - Differences with Bagging:baggingê³¼ì˜ ì°¨ì´ì 
        - Models are built sequentially on modified versions of the data
            - randomí•˜ê²Œ sampleëœê²Œ ì•„ë‹ˆë¼ weightì— ì˜í•´ sampleëœ dataì— ì˜í•´ í•™ìŠµ
        
        - The predictions of the models are combined through a weighted sum/vote
            - ì ì  hard sampleì— ëŒ€í•´ í•™ìŠµë˜ë‹ˆ easy sample / hard sampleì˜ classifierê°€ ë™ì¼í•œ weightë¥¼ ê°€ì§ˆ ìˆ˜ ì—†ìŒ : baggingì€ ë™ì¼í•œ ì¡°ê±´ìœ¼ë¡œ randomly sampling (no weight)
                - ê±°ì˜ ë™ë“±í•œ ì¡°ê±´ì´ê¸° ë•Œë¬¸ì— weightë¥¼ ì£¼ì§€ ì•ŠìŒ
                - boostingì˜ ê²½ìš° misclassifiedì— ëŒ€í•´ overfitting (hard sampleì´ ì¦ê°€í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ weight update)-> ensembleí•˜ë©´ ì ì  hard sample ì¶”ê°€ë˜ë©° overfitting ìœ„í—˜
- Random Forest
    
    RandomForest:
    
    - Averaging the prediction over a collection of trees constructed using a **randomly selected subset of features**
        - treeë¥¼ randomlyìƒì„±í•˜ì—¬ randomly selectí•´ì„œ ë§Œë“ ë‹¤.
    
    - Random Forest: A variation of the bagging algorithm - baggingì²˜ëŸ¼ ì—¬ëŸ¬ ê°œ ensemble
    - Created from individual decision trees
        - Diversity is guaranteed by selecting randomly at each split, a subset of the original features during the process of tree generation
        - **tree êµ¬ì¡° : unstable êµ¬ì¡° â†’ diversityê°€ guaranteedë¨ automatically**
    - R.F í™œìš©
        - During classification, each tree votes and the most popular class is returned
            - classificationì—ì„œëŠ” : voteë¥¼ ê°€ì¥ ë§ì´ ë°›ì€ classê°€ ìµœì¢… ê²°ê³¼ decision
        - During regression, the result is the averaged prediction of all generated trees
            - regressionì—ì„œëŠ” :ê° treeë“¤ì´ resultì„ ë§Œë“œëŠ”ë° ì´ë¥¼ average ì·¨í•˜ë©´ random forest result
    - random selectionì´ : feature selection / data sampling
- Heterogeneous ensembles:
    - Combining a set of **heterogeneous predictors**
        - NN + SVM + DT ë“± ìœµí•©
- Model Selection
    
    
    - Golden rule: there is no algorithm that is the best one for all the problems
        - í•˜ë‚˜ì˜ íŠ¹ì • ì•Œê³ ë¦¬ì¦˜ì´ ë‹¤ë¥¸ ëª¨ë“  problem ëª¨ë‘ë¥¼ í•´ê²°í•˜ì§€ëŠ” ì•ŠëŠ”ë‹¤
    - Typically, two approaches (or both) can be adopted:
        - To choose the algorithm more suitable for the given problem
        - To adapt the given data for the intended algorithm (using pre-processing, for instance)
            - ì£¼ì–´ì§„ dataë¥¼ ì˜ tuningí•  ìˆ˜ ìˆë„ë¡ í•œë‹¤ for ì‚¬ìš©í•˜ê³ ì í•˜ëŠ” algorithm (preprocessing)
    - The concept of â€œgood algorithmâ€ depends on the problem:
        - good algorithm : prob by prob
        - Explainability : modelì´ ì–´ë–¤ íŒë‹¨ì„ ë‚´ë¦°ë‹¤ë©´ íŒë‹¨ì˜ ì •í™•ë„ë„ ì¤‘ìš”í•˜ë‚˜ ê·¸ ê²°ì •ì˜ ì´ìœ ë„ ì¤‘ìš”í•¨ : bayesian, decision treeëŠ” ì‰½ê²Œ ì„¤ëª…í•  ìˆ˜ ìˆëŠ”ë° ê·¸ ì™¸ì—ëŠ” ì„¤ëª…ì´ ì‰½ì§€ ì•ŠìŒ
        - ë¶„ë¥˜ ê´€ë¦¬ ë¬¸ì œì— ìˆì–´ì„œëŠ” ì´ì†¡ ì‹œê°„ ì˜ˆì¸¡ ì •í™•ë„ê°€ ê°€ì¥ ì¤‘ìš”í•œ ì„ íƒìš”ì¸
        - For a doctor, the interpretation of the model can be a major criterion for the selection of the model (decision trees and Bayesian networks are very appreciated)
        - For logistics, the accuracy of travel time prediction is, typically, the most important selection criterion.
- Statistical Validation

# 12. Clustering

[12. Clustering](https://www.notion.so/12-Clustering-68dc57c409b94b27afd366a66f7d672c)

- **K-means clustering**
    
    
    An iterative clustering algorithm
    
    - Initialize: Pick K random points as cluster centers
        
        0. clusterì˜ ê°œìˆ˜ ê°€ì • : kê°œì˜ cluster = kê°œì˜ random point ì´ˆê¹ƒê°’ assume
        
    - Alternate:
        1. Assign data points to closest cluster center
            
            1. kê°œì˜ ptì— ëŒ€í•´ì„œ ê°ê°ì˜ dataë“¤ì„ ê°€ì¥ ê°€ê¹Œìš´ cluster centerì— í• ë‹¹í•˜ê³ 
            
        2. Change the cluster center to the average of its assigned points
            
            2. Cluster center update : ê° iterationë§ˆë‹¤ update
            
            - ë” ì´ìƒ updateë˜ì§€ ì•ŠëŠ” ì‹œì ì—ì„œ cluster ì¤‘ë‹¨
    - Stop when no point assignments change
        
        ì´ˆê¹ƒê°’ì— ëŒ€í•´ì„œ (initial center point) partition ë‚˜ëˆ”
        
        - ê·¸ dataë“¤ì˜ center meanì„ êµ¬í•´ì„œ ì´ë¡œ centerë¥¼ updateí•¨
        - ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ updateëœ ê°’ë“¤ì˜ memberë“¤ì„ ì¬í• ë‹¹
        - ë°˜ë³µí•˜ë‹¤ ë³´ë©´ ê°ê°ì˜ clusterì˜ centerë¡œ ì´ë™í•˜ê²Œ ë¨
- **K-means clustering properties**
    
    
    ## Properties of K-means algorithm (convergence)
    
    - Objective
        
        ëª¨ë“  sampleë“¤ì— ëŒ€í•´ì„œ centerê°’ì„ ê³„ì‚° :sampleë“¤ì˜ center ê°’ìœ¼ë¡œë¶€í„°ì˜ ê±°ë¦¬ ì œê³±ì˜ í•©ì´
        kê°œì˜ clusterì— ëŒ€í•´ì„œ ìµœì†Œ
        
        - cluster centerì— ì˜ ì¼ì¹˜í•˜ê²Œ ë˜ë©´, í•´ë‹¹ clusterì— ì†í•˜ëŠ” sampleë“¤ì´ ê·¸ cluster center ì™€ ì´ë£¨ëŠ” ê±°ë¦¬ì˜ í•©ì´ ëª¨ë“  clusterì— ëŒ€í•´ì„œ minimumì´ ë¨
        
        $$
        \min_{\mu} \min_{c}  \Sigma_{i=1}^{k} {\Sigma_{x\in C_i}|x-\mu_i|^2}
        $$
        
    - Fix $\mu$, optimize $C$
        
        iterationì‘ì—…- partition update
        
        - mu ê³ ì •, C optimize
        - centerê¹Œì§€ì˜ ëª¨ë“  sampleë“¤ì˜ ê±°ë¦¬ë¥¼ ìµœì†Œí™”í•˜ëŠ” ì‘ì—…
        
        $$
        \min_{c}  \Sigma_{i=1}^{k} {\Sigma_{x\in C_i}|x-\mu_i|^2} = \min_{c}  \Sigma_{i=1}^{n} {|x_i-\mu_{xi}|^2} 
        $$
        
    - Fix $\mu$, optimize $\mu$
        
        Partition updateí›„ centerê°’ update
        
        - ê° cluster sampleë“¤ì—ì„œ sampleë“¤ë¡œë¶€í„° center ê±°ë¦¬ë¥¼ ìµœì†Œí™”ì‹œí‚¬ ìˆ˜ ìˆë„ë¡ í‰ê· ê°’ ì„¤ì •
        - muì— ëŒ€í•´ì„œ ë¯¸ë¶„í•˜ê³ ã…¡ ì´ë¥¼ 0ìœ¼ë¡œ settingí•˜ë©´ í‰ê· ê°’ì´ë¼ëŠ” ê²ƒì€ ê° clusterì— ì†í•œ sampleë“¤ì˜ ê°’ì˜ í•©ì„ ê·¸ clusterì— ì†í•œ sampleë“¤ì˜ ê°’ì˜ í•©ì„ ê·¸ clusterì— ì†í•œ sampleë“¤ì˜ ê°œìˆ˜ë¡œ ë‚˜ëˆˆ ê°’ì´ ê·¸ center ê°’ : center mean
        
        $$
        \min_{\mu} \Sigma_{i=1}^{k} {\Sigma_{x\in C_i}|x-\mu_i|^2}
        $$
        
        - Take partial derivative with respect to $\mu_i$and sets to zero, we have $\mu_i = \frac 1 {C_i} \Sigma_{x\in C_i} x$
    - K-means takes an alternating optimization, each step is guaranteed to decrease the objective â€“ thus guaranteed to converge
- **Agglomerative clustering**
    
    
    - Agglomerative clustering
        - First merge very similar instances
            - ë¹„ìŠ·í•œ dataë¼ë¦¬ grouping : ì²˜ìŒì—ëŠ” ëª¨ë“  data ptê°€ ê°œë³„ clusterë¡œ ë˜ê³  ì ì°¨ í•˜ë‚˜ì˜ groupì´ ë  ë•Œê¹Œì§€ groupí™”
        - Incrementally build larger clusters out of smaller clusters
            - ê°€ì¥ similarityê°€ í° dataë¼ë¦¬ groupí™”í•¨ :
                - 1,3ì„ í•˜ë‚˜ì˜ groupìœ¼ë¡œ ë¬¶ê³  2, 5 groupìœ¼ë¡œ ë¬¶ì´ê²Œ ë˜ë©´ 1st-2nd groupê°„ ê±°ë¦¬ëŠ” ê°€ì¥ ê°€ê¹Œìš´ ê±°ë¦¬ë¡œ í•  ê²ƒì¸ì§€ (1-2) ë¨¼ ê±°ë¦¬ë¡œ í•  ê²ƒì¸ì§€ (3-5) í‰ê· ìœ¼ë¡œ í•  ê²ƒì¸ì§€ì— ë”°ë¼, similarity íŒë‹¨ ê¸°ì¤€ì— ë”°ë¼ clusteringì´ ë‹¤ë¥´ê²Œ ë¨
    - Algorithm:
        - Maintain a set of clusters, Initially, each instance in its own cluster
        - Repeat:
            - Pick the two closest clusters
            - Merge them into a new cluster
            - Stop when thereâ€™s only one cluster left
    - Produces not one cluster, but a family of clusters represented by a dendrogram
    
    ![Untitled](Final/12/Untitled.png)
    
    - How should we define â€œcloseâ€ for clusters with multiple elements?
        - similarityë¥¼ ì–´ë–»ê²Œ íŒë‹¨í•  ê²ƒì¸ê°€  =(distanceë¥¼ ì–´ë–»ê²Œ ê³„ì‚°í•  ê²ƒì¸ê°€)
        - closest / Farthest / Average â†’ clusterê°€ ë‹¬ë¼ì§€ê²Œ ë¨
            
            ![Untitled](Final/12/Untitled_1.png)
            
    - Many options:
        - Closest pair (single-link clustering)
        - Farthest pair (complete-link clustering)
        - Average of all pairs
    - Different choices create different clustering behaviors
- **Agglomerative clustering - hierarchical clustering : strength, complexity**
    
    
    ## Strengths of Hierarchical Clustering
    
    - No assumptions on the number of clusters
        - cluster ê°œìˆ˜ ê°€ì •í•˜ê³  ìˆ˜í–‰í•˜ê²Œ ë¨
        - ë‹¨) cluster ê°œìˆ˜ ì˜ëª» ì˜ˆì¸¡í•˜ë©´ algorithm ì¢‹ì§€ ì•Šì€ ê²°ê³¼ë¥¼ ë‚¼ ê²ƒ
        - Any desired number of clusters can be obtained by â€˜cuttingâ€™ the dendogram at the proper level
    - Hierarchical clusterings may correspond to meaningful taxonomies
        - cluster ëª‡ ê°œì¸ì§€ ëª¨ë¥´ëŠ” ìƒíƒœì—ì„œ clustering
        - clustering : dendrogram ê·¸ë ¤ì„œ duration ê¸´ êµ¬ê°„ì„ íŒë‹¨í•˜ì—¬ cluster ê°œìˆ˜ ê²°ì • / ì ì ˆí•œ ìƒíƒœì—ì„œ dendrogram cutting
        - ëŒ€ì¹­ì  ë¶„ë¥˜ : phylogeny. Catalog
        - Example in biological sciences (e.g., phylogeny reconstruction, etc), web (e.g., product catalogs), etc.
    
    ## Complexity of hierarchical clustering
    
    - Distance matrix is used for deciding which clusters to merge/split
        - distance <-> proximity
    - data point nê°œê°€ ìˆë‹¤ë©´, n by nê°œ distanceë¥¼ ëª¨ë‘ ê³„ì‚°í•¨ : n^2 ì—°ì‚°
        - At least quadratic in the number of data points
            - Not usable for large datasets
    
    groupí™”ê°€ ì§„í–‰ë˜ë©° Matrix í¬ê¸°ê°€ ì ì°¨ ì¤„ì–´ë“¤ê²Œ ë˜ì–´ ìµœì¢…ì ìœ¼ë¡œ í•˜ë‚˜ì˜ blockë§Œ ë‚¨ê²Œ ë¨
    
- **Closest pair (single-link clustering)**
    
    
    - Each cluster is a set of points
    - How do we define distance between two sets of points
    - Lots of alternatives
    - Not an easy task
    
    - Single-link distance between clusters Ci and Cj is the minimum distance between any object in Ci and any object in Cj
        - Single link : shortest distance
    - The distance is defined by the two most similar objects
        
        $$
        D _{s l} ( C _i , C _j ) = \min _{x , y} (d ( x , y )| x \in C _i , y \in C _j ) 
        $$
        
    
    # Single-link clustering: example
    
    - Determined by one pair of points, i.e., by one link in the proximity graph
        
        Diagonal valueë¥¼ ë³´ê³  íŒë‹¨í•  ìˆ˜ ìˆìŒ
        
        ê°™ì€ ìš”ì†Œì— ëŒ€í•œ ê°’ì´ 1-> similarity
        
        - data ë¶„í¬ì— ì˜í•˜ë©´ 1,2,3,4,5 clustering
        - symmetric : ëŒ€ê°ì„  ì•„ë˜ ë¶€ë¶„ì€ í¬ê²Œ ì˜ë¯¸ê°€ ì—†ìŒ
        - ê°’ì´ ë†’ì€ ìˆœëŒ€ë¡œ ë¨¼ì € clusterë¥¼ í˜•ì„±í•˜ê²Œ ë¨
- **Farthest pair (complete-link clustering)**
    
    
    ## Distance between two clusters
    
    - Complete-link distance between clusters Ci and Cj is the maximum distance between any object in Ci and any object in Cj
    - The distance is defined by the two most dissimilar objects
        
        ê°€ì¥ ë¨¼ ê±°ë¦¬ì˜ simple pairì— ëŒ€í•´ì„œ dataë¥¼ clustering (Most dissimilar)
        
        Most similar
        
    
    $$
    D _{s l} ( C _i , C _j ) = \max _{x , y} (d ( x , y )| x \in C _i , y \in C _j ) 
    $$
    
    ## Complete-link clustering: example
    
    - Distance between clusters is determined by the two most distant points in the different clusters
        
        ê±°ë¦¬ íŒë‹¨í•œ ì´í›„(ì°¨ì´-dissimilar)
        clusterë¼ë¦¬ ë³‘í•©í•  ë•ŒëŠ” ê°€ì¥ ê°€ê¹Œìš´ ê²ƒ ë¼ë¦¬ (ë™ì¼)
        
- **Average of all pairs**
    
    
    # Distance between two clusters
    
    - Group average distance between clusters Ci and Cj is the average distance between any object in Ci and any object in Cj
        - ì „ì²´ data pairì˜ average ì´ìš©
        - I cluster , j cluster : í‰ê·  distance ê³„ì‚°í•œ í›„ shortest path ê²°ì •
    
    $$
    D_{avg} (C_i, C_j) = \frac 1 {|C_i| \times |C_j| } \Sigma_{x\in C_i, y \in C_j} d(x,y)
    $$
    
- **statistical validation**

# 13. Dimensionality Reduction

[13. Dimensionality Reduction ](https://www.notion.so/13-Dimensionality-Reduction-c21c309ea0724478ba6924d6ce913f81)

- **Goal of Dimensionality Reduction**
    
    Visualization ìš©ì´ : 3dim ì´í•˜ë¡œ Reduct â†’ visualize easy
    
    Performance í–¥ìƒ : easy to handle data
    
    Computation cost ê°ì†Œ 
    
- **Data Compression**
    
    (í•„ìš”ì„±) Too high dimension of detection windows : computationally intensive
    
    - Cannot handle them : too high dimensionality â†’ pixel diminishì‹œì¼œ ì‚¬ìš©
    - Curse of dimensionality : ë„ˆë¬´ Data dimensionì´ ë†’ì•„ì§€ë©´ accuracyê°€ ë–¨ì–´ì§€ëŠ” í˜„ìƒ
        - booleanì´ ì•„ë‹Œ Observed value (measured) : booleanì´ ì•„ë‹ˆë¼ acc ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ
- **Feature Extraction**
    
    (ê³¼ì •) very high-dim raw data â†’ feature extraction dimension reduction â†’ classifier
    
- **dimension reduction**
    
    axisì— projectioní•œ í˜•íƒœë¡œ reduct dimension
    
- **ì™œ ì¢Œí‘œì¶•ì„ rotateí•œ ê²ƒì´ë¼ê³  í‘œí˜„í•˜ëŠ”ê°€? (multivariate dataset into new config)**
    - simplify data
    - easy to look at rel. between variable - patterns of units
- **PCA process**
    - [goal] find k-dim projection  which preserves best variance
    
    1. compute mean vector $\mu$ and covariance matrix $\Sigma$ of original data 
        1. D-dim dataë¡œë¶€í„° Mean, Covariance êµ¬í•¨
        2. $X = [X1, X2, â€¦ , Xn]$
        3. (mean centered X) $X_{\mu_0} = X-\mu = [X1-\mu, X2-\mu, â€¦ , Xn-\mu]$
        4. $\Sigma = X_{\mu_0} X_{\mu_0} ^T = \frac 1 n  \Sigma (X_i - \mu)(X_i - \mu)^T$
        5. $S = \Sigma(X_i - \mu)(X_i - \mu)^T$
        6. $\Sigma v = \lambda v$
    2. Compute eigenvectors and eigenvalues of $\Sigma$ 
    3. Select top k eigenvectors
        1. Top kê°œ eigenvalueì— ëŒ€ì‘í•˜ëˆˆ eigenvector êµ¬í•¨
    4. Project points onto subspace spanned by them 
        1. $y = A(x-\mu)$
        2. where y is the new data, x is the original data, and the rows of A are the eigenvectors
    5. When we said the eigenvector as 
    
    ![Untitled](Final/13/Untitled.png)
    
    in the previous lecture, $A$ is $V^T$ (k vectors, $v_1$ â€¦ $v_k$)
    
- **PCA  - Eigenvalue, vectorì˜ ì˜ë¯¸?**
    - **eigenvector :PCAë¶„ì„ì„ í–ˆì„ ë•Œ dataê°€ ê°€ì¥ í¬ê²Œ ë¶„ì‚°ëœ ë°©í–¥ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ë°©í–¥ë²¡í„°ì´ê³  ê·¸ ì •ë„ë¥¼ ê°€ë¦¬í‚¤ëŠ” ê²ƒì€ eigenvalue.**
    - smaller eigenvalue ìˆœ - eigenvector ì •ë ¬ â†’ í¬ê²Œ varë˜ëŠ” ë°©í–¥ìœ¼ë¡œ ì •ë ¬
    - ê°€ì¥ í° eigenvectorë¡œ í•˜ì—¬ ì¢Œí‘œì¶•ì„ ë³€í™˜í•´ë„ dataë“¤ì´ ì˜ í‘œí˜„ì´ ë¨
        - dataë¥¼ Eigenvectorì— Projection : ìƒˆë¡œìš´ ì¢Œí‘œê°’ìœ¼ë¡œ ë‚˜ì˜¤ê²Œ ë¨
    
    - Covariance matrix :
        - d dimension dataë¡œë¶€í„° dê°œì˜ eigenvector
        - 2ì°¨ì› dataë¡œë¶€í„° 2ê°œì˜ eigenvector, eigenvalue
        - 
    - **The eigenvectors of $\Sigma$ define a new coordinate system 
    (ìƒˆë¡œìš´ coordinate systemìœ¼ë¡œ ì ìš©)**
        - Eigenvector with largest eigenvalue captures the **most variation** among data X
            - **eigenvector :PCAë¶„ì„ì„ í–ˆì„ ë•Œ dataê°€ ê°€ì¥ í¬ê²Œ ë¶„ì‚°ëœ ë°©í–¥ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ë°©í–¥ë²¡í„°ì´ê³  ê·¸ ì •ë„ë¥¼ ê°€ë¦¬í‚¤ëŠ” ê²ƒì€ eigenvalue.**
        - Eigenvector with smallest eigenvalue has least variation
            - **ê°€ì¥ ì‘ì€ eigenvalueì— ëŒ€ì‘ë˜ëŠ” EigenvectorëŠ” ë¶„ì‚°ì´ ì œì¼ ì‘ë‹¤.**
            ![Untitled](Final/13/Untitled_1.png)
            
            - v1ì´ë¼ëŠ” axisë¡œ íˆ¬ì˜í•œë‹¤ë©´ Dataê°€ ê°€ì¥ ì˜ ë¶„ì‚°ë˜ëŠ” ìµœì ì˜ ë°©í–¥ì´ë‹¤ â†’ ìµœëŒ€ ë¶„ì‚° ë°©í–¥ìœ¼ë¡œ ì••ì¶•ë˜ë©´ ì œì¼ ì˜ ë¶„ì‚°ë˜ëŠ” ë°©í–¥ìœ¼ë¡œ dataì˜ ì°¨ì›ì„ ì¶•ì†Œì‹œí‚¤ëŠ” ê²ƒì´ê¸°ì— ì›ë³¸ Data ì •ë³´ ì˜ ë°˜ì˜
        - Dimension reductionì— ë”°ë¥¸ ì›ë³¸ dataì˜ information lossì •ë„
            - 1Dim ì••ì¶• : ê°€ì¥ ìµœì†Œ eigenvector, 2Dim ì••ì¶• : ë‘ ë²ˆì§¸eigenvector
            - d dimì— ëŒ€í•´ì„œ Dê°œë¥¼ ëª¨ë‘ ì‚¬ìš© â†’ ì–´ë– í•œ ì†ì‹¤ë„ ì—†ì´ ì›ë³¸ Data ìˆ˜í–‰ ê°€ëŠ¥
                1. í‘œí˜„ëœ DataëŠ” ë™ì¼í•˜ì§€ë§Œ PCA ë¶„ì„ì´ ë˜ì–´ ìˆê¸°ì— Dimensionì„ ì¤„ì´ë©´ ë¨
                2. corelationì´ ê°ì†Œëœ í˜•íƒœë¡œ ì¢Œí‘œì¶• ì •ë¦½ : x1ì˜ ê°’ì´ ë³€í™”í•  ë•Œ x2ì˜ ê°’ì´ ë³€í™”ë˜ëŠ” ì •ë„
- **LDA**
    
    LDA : labeled 
    
    - PCAëŠ” unsupervised learningì—ì„œ clustering, dimensionality reduction
        - Not for classification
    - LDAëŠ” supervised learning, dimensionality reduction
        - Classificationì„ ìœ„í•´ ì“¸ ìˆ˜ ìˆìœ¼ë‚˜ label ì‚¬ìš©í•´ì„œ unsupervisedë¼ê³  ë³¼ ìˆ˜ëŠ” ì—†ìŒ
    
    LDAì˜ í•„ìš”ì„±
    
    - PCA maximizes the total scatter â†’ PCA does not consider class information
        - PCA ë¶„ì„ í•˜ë©´ dataì˜ ìµœëŒ€ ë¶„ì‚° ë°©í–¥ìœ¼ë¡œ eigenvectorê°€ ì–»ì–´ì§€ê²Œ ë¨
        - ìµœëŒ€ ë¶„ì‚° ë°©í–¥ìœ¼ë¡œ data íˆ¬ì˜í•˜ê²Œ ë˜ë©´ data label êµ¬ë¶„ì´ ì—†ì–´ì§ (ì„ì„)
- **PCA vs. LDA**
    
    
    - PCA maximizes projected total scatter
    labelì´ ì—†ìœ¼ë‹ˆ ì „ì²´ dataì— ëŒ€í•´ì„œ covarianceë¥¼ êµ¬í•¨
        
        $$
        \Sigma = \frac 1 N \Sigma_{i=1}^{N}{(x_i -\mu)(x_i -\mu)^T}
        $$
        
        $$
        \Sigma v = \lambda v
        $$
        
    - LDA maximizes ratio of projected between-class to projected within-class scatter
        - LDA: ê° classë³„ë¡œ covariance matrixë¥¼ êµ¬í•¨
            - within class scatter
        - Eigen-decomposition: Sigma valueê°€ ìµœëŒ€í™”ë˜ëŠ” ë°©í–¥ :
            - pca : covariance ìµœëŒ€í™”
            - lda : $\Sigma_b$ ìµœëŒ€í™”, $\Sigma_w$ ìµœì†Œí™”
        - cluserì˜ ë¶„ì‚°ì´ ê°ê° cluster ë‚´ë¶€ì—ì„œëŠ” covê°€ ìµœì†Œ
        ì„œë¡œ ë‹¤ë¥¸ class ê°„ì—ëŠ” cov ìµœëŒ€ì˜ ë°©í–¥
        
        $$
        \Sigma_w = \Sigma_{j=1}^{c}\frac 1 {N_c} \Sigma_{i=1}^{N_c}{(x_i -\mu_c)(x_i -\mu_c)^T}
        $$
        
        $$
        \Sigma_c = \frac 1 {c} \Sigma_{i=1}^{c}{(\mu_c-\mu)(\mu_c-\mu)^T}
        $$
        
        $$
        \frac{\Sigma_b}{\Sigma_w}v = \lambda v
        $$
        
    
    ## PCA vs. LDA (for reference)
    
    - eigenvector PCA = var ìµœëŒ€ ë°©í–¥ìœ¼ë¡œ vectorë¥¼ êµ¬í•¨
        - ì›ë˜ vectorë¥¼ transformationí•˜ì—¬ varì´ ìµœëŒ€í™”ë˜ë„ë¡
    - $z = w^Tx$
    - Maximize $||z|| = z^Tz$  , while $||w|| = w^Tw = 1$
        - zë¥¼ maximize = |z| ìµœëŒ€ = z^Tz ìµœëŒ€í™”
        - ì•ì—ì„œ ì´ weight matrixëŠ” norm =1ì´ ë˜ëŠ” ë°©í–¥ìœ¼ë£Œ í‘œì¤€í™”í•´ë†“ê³  z ìµœëŒ€í™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ eigenvalue vector êµ¬í•¨ â†’ $z^Tz$
    - $z^Tz = w^Tx(w^Tx)^T = w^Tx x^Tw = w^T \Sigma w$
    - $\max_w{(z^Tz - \lambda(w^T w-1))} = \max_w{(w^T \Sigma w - \lambda(w^Tw-1))}$
    
    - Take derivative w.r.t. $w$
    - $2 \Sigma w - 2 \lambda w = 0$
    - $\Sigma w = \lambda w$
- **Eigenface**
    
    x new = sigma wi xi
    
    - dataì˜ Weighted sumìœ¼ë¡œ ë‚˜ì˜¨ë‹¤ : linear data
    - whoe data to DNN â†’ ë” íš¨ê³¼ì ì´ë”ë¼

# 14. RL

[14. Reinforcement Learning](https://www.notion.so/14-Reinforcement-Learning-0fffcc707ee9413a90b11ae19e6be037)

- **Characteristics of Reinforcement Learning**
    - Feedback is delayed, not instantaneous
    - Time really matters (sequential, non i.i.d. data)
        - ì‹œê°„ì´ ì¤‘ìš”í•œ ìš”ì†Œ ì¤‘ í•˜ë‚˜
        - sequential : ì „ë°˜ì˜ ì„ íƒì´ í›„ë°˜ì˜ ì„ íƒì— ì˜í–¥
        iid = independent identically distributed - ìƒí˜¸ ì—°ê´€
    - Agentâ€™s actions affect the subsequent data it receives
        - agent actionì´ ì´í›„ dataì— ì˜í–¥ì„ ë¯¸ì¹œë‹¤.
    - **Goal: select actions to maximize total future reward**
        - ì¼ë ¨ì˜ í–‰ë™ì— ë”°ë¥¸ rewardê°€ ìµœëŒ€ê°€ ë˜ë„ë¡ í•™ìŠµí•œë‹¤
- **Diff. with supervised, unsupervised learning**
    - What makes reinforcement learning different from other machine learning paradigms?
    - supervised l. vs unsupervised l. vs. RL
        - supervised : label + data
        - Unsupervised : just use given data
        - RL : data + reward - Rewardì— í•´ë‹¹í•˜ëŠ” ì¶”ê°€ì ì¸ inputì´ ì¡´ì¬í•¨
    
    â†’ There is no supervisor, only a reward signal
    
- **Rewards**
    - Indicate show well agent is doing at step t & The agentâ€™s job is to maximize cumulative reward
    - ê°ê°ì˜ ì‹œê°„ì— ì–¼ë§ˆë‚˜ ì˜ í–‰ë™ í–ˆëŠ”ì§€ ë³´ê³  reward ìµœëŒ€í™”ë˜ëŠ” ë°©í–¥ìœ¼ë¡œ í–‰ë™í•˜ë„ë¡ í•™ìŠµ
    - Reinforcementlearning is based on the reward hypothesis
        - reward = ì‚¬ëŒì´ ë§Œë“  ê¸°ì¤€
        ex. Atari game : target ë³„ ìµœëŒ€í•œì˜ ì ìˆ˜ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•™ìŠµì´ ë˜ê¸°ë„ í•¨. ì ìˆ˜ê°€ ë§ì€ ìª½ì„ ë” ë¹¨ë¦¬ ì–»ì„ ìˆ˜ ìˆë„ë¡ í•™ìŠµì‹œí‚¤ëŠ” ì–‘ìƒì´ ìƒê¸¸ ìˆ˜ ìˆë‹¤,
        - Reward hypothesis: all goals can be described by the m**aximization of expected cumulative reward**
    - Reward may be delayed rewardëŠ” delayë¥¼ ìˆ˜ë°˜í•˜ì—¬ ì£¼ì–´ì§ˆ ìˆ˜ ìˆë‹¤
    - í˜„ì¬ actionìœ¼ë¡œ ì¸í•œ rewardì— ë” ì¤‘ì ì„ ë‘˜ ê²ƒì¸ì§€, ë¯¸ë˜ì˜ rewardì— ì¤‘ì ì„ ë” ë‘˜ ê²ƒì¸ì§€ : user settingí•  ìˆ˜ë„ ìˆê³  í•™ìŠµ ë‹¨ê³„ì—ì„œ ì–´ë–»ê²Œ parameterë¥¼ ì„¤ì •í–ˆëŠ”ì§€ì— ë”°ë¼ / í•™ìŠµì´ ì˜ íš¨ê³¼ì ìœ¼ë¡œ ì´ë£¨ì–´ì§ˆìˆ˜ ìˆëŠ”ì§€ë¥¼ ê³ ë ¤í•˜ì—¬ ëª¨ìˆ˜ ì¡°ì •
        - (greedy) í˜„ì¬ rewardì— ì´ˆì ì„ ë§ì¶”ëŠ” ê²½ìš° - current reward
        - (optimal) ì „ì²´ rewardì— ì´ˆì ì„ ë§ì¶”ëŠ” ê²½ìš° - total reward
            - Itmay be better to sacrifice immediate reward to gain more long-term reward (greedy optimal)
- **êµ¬ì„± of RL**
    - At each stept the agent: agentê°€ ì£¼ë³€ì„ ê´€ì°°í•˜ê³ , rewardë¥¼ ë°›ì•„ actionì„ ì·¨í•¨
        - Executes action At
        - Receives observation Ot
        - Receives scalar reward Rt
    - An RL agent may include one or more of these components:
        - Policy: agentâ€™s behavior function í–‰ë™ ì •ì˜
        - Value function: how good is each state and/or action ì–¼ë§ˆë‚˜ ì¢‹ì€ê°€
        - Model: agentâ€™s representation of the environment  í•™ìŠµ ëª¨ë¸
    
    <agent, environmentì˜ ìƒí˜¸ì‘ìš©>
    agentëŠ” actionì„ ì·¨í•˜ê³  stateì— ë”°ë¼ Rewardë¥¼ ë°›ê²Œ ë¨
    envëŠ” actionì„ ë°›ì•„ë“¤ì—¬ì„œ agentì—ê²Œ ì£¼ê³  ë³€í™˜ëœ statementë¥¼ agentì—ê²Œ ì¤Œ
    
    - tíƒ€ì„ìœ¼ë¡œ ì´ë£¨ì–´ì§€ëŠ” ìš”ì†Œë“¤
- **Bellman Eq**
    
    $$
    V(s) = max_a(R(s,a) + \gamma V(s'))
    $$
    
    - $R(s,a)$Â : reward: stateì—ì„œ ì·¨í•œ actionì— ë”°ë¥¸ reward
    - $V(s)$ : is the value function - value function:ì „ì²´ reward ë¥¼ ì–´ë–»ê²Œ í‘œí˜„í•  ê²ƒì¸ê°€
    - $\gamma$ : is the discounting factor
        - í˜„ì¬-ë¯¸ë˜ rewardì¤‘ ì–´ëŠ ê²ƒì— ì´ˆì ì„ ë§ì¶œ ê²ƒì¸ì§€ ì¤‘ìš”ë„ ë§ì¶”ëŠ” ìƒìˆ˜
    - $s'$ : is the next state agent can go from
        - s : í˜„ì¬ state, sâ€™ : next state
    
    $$
    V(s) = max_a(R(s,a) + \gamma V(s'))
    $$
    
    - By calculating V(s) for all states
        - Agent can move to the state with larger state value
    - ì„ì˜ì˜ ì¶œë°œì ì—ì„œ state function ì»¤ì§€ëŠ” ìª½ìœ¼ë¡œ actionì„ ì·¨í•˜ë©´ ëœë‹¤
    â†’ equationì„ ì´ìš©í•´ì„œ value funcitionì„ êµ¬í•œí›„ ìµœì ì˜ pathë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤
- **Sequential Decision Making**
    - í˜„ì¬ì˜ actionì´ ë‹¤ìŒ í„´ actionì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ë°, ì˜¤ëœ turnì— ëŒ€í•´ ì˜í–¥ì„ ë¼ì¹ ìˆ˜ë„ ìˆìŒ.
    - Actions may have long term consequences
        - stateê°€ ìˆê³  actionì„ ì·¨í•´ì„œ s1-(a1)->s2-(a2)->s3