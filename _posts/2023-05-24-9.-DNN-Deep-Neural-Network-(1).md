---
layout: post
date: 2023-05-24
title: "9. DNN Deep Neural Network (1)"
tags: [ML, ]
categories: [Notes, ]
use_math: true
---


ë°•ìš´ìƒ êµìˆ˜
Office: R-911
Tel: 705-8936
Email: [unsangpark@sogang.ac.kr](mailto:unsangpark@sogang.ac.kr)



# Deep Learning

- A machine learning subfield. Exceptional performance in learning patterns.
- Deep learning algorithms attempt to learn (multiple levels of) representation by using a hierarchy of multiple layers.
- If you provide the system tons of information, it begins to understand it and respond in useful ways.

![0](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/0.png)

- Manually designed features are often over-specified, incomplete and take a long time to design and validate
- Learned Features are easy to adapt, fast to learn
- Deep learning provides a very flexible, (almost?) universal, learnable
framework for representing world, visual and linguistic information.
- Can learn both unsupervised and supervised
- Effective end-to-end joint system learning
- Utilize large amounts of training data

## History

- In ~2012, deep learning (DL) started outperforming other machine learning (ML) techniques, first in speech and vision, then NLP

![1](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/1.png)


![2](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/2.png)


![3](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/3.png)


## Structure


ì–´ë–»ê²Œ DLì´ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ëŠ”ê°€?

- Fat + Short vs. Thin + Tall Networks
- The same number of parameters

![4](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/4.png)

- Deep â†’ Modularization
- 

![5](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/5.png)


![6](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/6.png)


![7](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/7.png)


![8](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/8.png)


![9](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/9.png)







![10](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/10.png)


![11](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/11.png)

- Before 2006, deeper usually does not imply better performance.
- [Geoffrey Hinton showed how to train deep network in 2006 [1]](/a8916a1612b345718745d8cf339ab58b)
	- Learned layers one by one
- [Deep Neural Networks showed good classification performance with large image data set in 2012. [2] ](/a8916a1612b345718745d8cf339ab58b)
	- GPU
	- Big data
	- Better learning algorithms

![12](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/12.png)


[http://www.gizmodo.com.au/2015/04/the-basic-recipe-for-machinelearning-explained-in-a-single-powerpoint-slide/](http://www.gizmodo.com.au/2015/04/the-basic-recipe-for-machinelearning-explained-in-a-single-powerpoint-slide/)

- Rectified Linear Unit (ReLU)
	- Fast to compute
	- Vanishing gradient problem

![13](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/13.png)

- [[Xavier Glorot, AISTATSâ€™11] [3]](/a8916a1612b345718745d8cf339ab58b)
- [[Andrew L. Maas, ICMLâ€™13] [4]](/a8916a1612b345718745d8cf339ab58b)
- [[Kaiming He, arXivâ€™15] [5]](/a8916a1612b345718745d8cf339ab58b)

# Dropout


[Dropout [6]](/a8916a1612b345718745d8cf339ab58b)

- Each time before computing the gradients
- Each neuron has $p \times 100 \%$ chance to be dropped
	- The structure of the network is changed
- Use the new network for training

![14](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/14.png)


![15](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/15.png)

- Weights should be multiplied by (1-p) when testing

## Training stage 


Assume dropout rate is 50% 


![16](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/16.png)


### Testing stage


No dropout


![17](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/17.png)


# Convolutional Neural Network


## Fully connected layer

- Example: 200x200 image * 40K hidden units â†’ ~2B parameters

![18](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/18.png)_Slide Credit: Marc'Aurelio Ranzato_

- Waste of resources + we have not enough training samples
- Spatial correlation is local

## Locally Connected Layer

- Example: 200x200 image * 40K hidden units â†’ ~4M parameters (Filter size: 10x10)
Page 20- Spatial correlation is local

![19](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/19.png)

- Waste of resources + we have not enough training samples
- Spatial correlation is local

![20](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/20.png)

- Statistics is similar at different locations
	- Share the same parameters across
- different locations (weight sharing)
	- Convolutions with learned kernels

## Convolution operation


$F(m,n) = f * h = \Sigma_{l= -\frac w 2}^{\frac f 2}\Sigma_{k= -\frac w 2}^{\frac w 2} {f(m+k, n+l) *h(\frac w 2 -k, \frac w 2 -l)}$


![21](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/21.png)


![22](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/22.png)

- If a feature is useful in some locations during training, detectors for that feature will be useful in all locations during testing

![23](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/23.png)


## Pooling

- By â€œpoolingâ€ (e.g., taking max) filter responses at different locations, we gain robustness to the exact spatial location of features.

![24](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/24.png)


![25](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/25.png)


![26](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/26.png)


### Max-pooling


$h_i^n(r,c) = max_{\bar r \in N(r), \bar c \in N(c), } h_i^{n-1} (\bar r, \bar c)$


### Average-pooling


$h_i^n(r,c) = mean_{\bar r \in N(r), \bar c \in N(c), } h_i^{n-1} (\bar r, \bar c)$


### L2-pooling


$h_i^n(r,c) = \sqrt{\Sigma_{\bar r \in N(r), \bar c \in N(c), } h_i^{n-1} (\bar r, \bar c)}$


## Convolution kernel (filter) examples


![27](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/27.png)

- Examples of learned object parts from object categories

	![28](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/28.png)


## LeNet-5 (1998)


[[7] Le-Net](/a8916a1612b345718745d8cf339ab58b)

- Yann LeCun and his collaborators developed a really good recognizer for
handwritten digits by using backpropagation in a feedforward net with
	- Many hidden layers (at that time),
	- 3 convolution layer,
	- 2 subsampling (pooling) layer
	- 5*5 convolution kernels,
	- ~340,000 connections,
	- ~60,000 parameter
- Used for reading ~10% of the checks in North America

	![29](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/29.png)


![30](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/30.png)


![31](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/31.png)


![32](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/32.png)


## Backpropagation in CNN

- Same color shares the same weight
- Compute the gradients as usual, and then modify the gradients so that they satisfy the constraints

![33](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/33.png)


![34](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/34.png)

- The 82 errors made by LeNet5
- Notice that most of the errors are cases that people find quite easy.
- The human error rate is probably 20 to 30 errors.
- LeNet uses knowledge about the invariances to design:
	- local connectivity
	- weight-sharing
	- Pooling
	- ~ 80 errors
- Using many different transformations of the input and other tricks (Ranzato2008)
	- ~ 40 errors
- Using carefully designed extra training data (Ciresan 2010)
	- For each training image, they produced many new training examples by applying many different transformations
	- ~ 35 errors

[Ciresan 2010][8]


![35](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/35.png)_PyTorch implementation of LeNet-5 for MNIST, https://github.com/radsn/LeNet5_

- The top printed digit is the right answer.
- The bottom two printed digits are the networkâ€™s best two guesses.
- The right answer is almost always in the top 2 guesses.
- With model averaging they can now get about 25 errors.

# From Handwritten Digits to 3-D objects

- Recognizing real objects in color photographs downloaded from the web is much more complicated than recognizing hand-written digits:
	- Hundred times as many classes (1000 vs 10)
	- Hundred times as many pixels (256* 256 color vs. 28* 28 gray)
	- Two dimensional image of three-dimensional scene
	- Multiple objects in each image
	- Cluttered background
- Will the same type of convolutional neural network work?

# The ILSVRC-2012 Competition on ImageNet


![36](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/36.png)

- [9] ImageNet
	- Over 15 million labeled high-resolution images
	- Roughly 22,000 categories
	- Collected from the web
	- Labeled by human using Amazonâ€™s Mechanical Turk crowd-sourcing tool
- ImageNet Large-Scale Visual Recognition Challenge (ILSVRC)
	- Uses a subset of ImageNet
	- 1,000 categories
	- 1.2 million training images
	- 50,000 validation images
	- 150,000 test images
- The classification task:
	- Get the â€œcorrectâ€ class in your top 5 bets. There are 1000 classes.
- The localization task:
	- For each bet, put a box around the object. Your box must have at least 50%
	overlap with the correct box.
- Some of the best existing computer vision methods were tried on this dataset by leading computer vision groups from Oxford, INRIA, XRCE(XEROX), â€¦
	- Computer vision systems use complicated multi-stage systems
	- The early stages are typically hand-tuned by optimizing a few parameters

## Examples from the test set (with the networkâ€™s guesses)


![37](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/37.png)


Error rates on the ILSVRC-2012 competition


|                                          | classification | classification & localization |
| ---------------------------------------- | -------------- | ----------------------------- |
| UToronto
                                | 16.4%          | 34.1%                         |
| UTokyo                                   | 26.1%          | 53.6%                         |
| Oxford University Computer Vision Group
 | 26.9%          | 50.0%                         |
| INRIA + XRCE                             | 27.0%          |                               |

undefined- UToronto (deep learning - Alex Krizhevsky, AlexNet)
- INRIA (French national research institute in CS) + XRCE (Xerox Research Center Europe)

# A CNN for ImageNet


AlexNet[10]

- Alex Krizhevsky (NIPS 2012) developed a very deep convolutional neural net of the type pioneered by Yann LeCun.
- 7 hidden layers not counting some max pooling layers
- The early layers are convolutional, the last two layers are fully connected
- The activation functions are
	- Rectified linear units in every hidden layer. These train much faster and are more expressive than sigmoid.
	- Normalization for better activation
- Use â€œdropoutâ€ to regularize the weights in the fully connected layers
- 224*224 patches are taken from the 256*256 images (10 different versions) and leftright reflections are used to get more data
- Used all 10 different patches at test time

![38](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/38.png)


## More examples from AlexNet


![39](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/39.png)


## Hardware for AlexNet

- He uses a very efficient implementation of convolutional nets on two NvidiaGTX 580 Graphics Processor Units (over 1000 fast little cores)
	- GPUs are very good for matrix-matrix multiplies.
	- GPUs have very high bandwidth to memory.
	- This allows him to train the network in a week.
	- It also makes it quick to combine results from 10 patches at test time.
- We can spread a network over many cores if we can communicate the states fast enough.
- As cores get cheaper and datasets get bigger, big neural nets will improve faster than old-fashioned computer vision systems.

# Evolution of the DNN

- Network depths and the performance
- ILSVRC classification error (top-5 error)

	![40](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/40.png)


# Fully Convolutional Networks

- Fully connected layer constrains the input image size

	![41](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/41.png)

- Fully convolutional network structure has no constrains on the input image size

	![42](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/42.png)


# Machine Learning, Deep Learning, Data Mining, Big data


## Big Data

- ê¸°ì¡´ ë°ì´í„°ì˜ í¬ê¸° ë²”ì£¼ë¥¼ë„˜ì–´ì„œëŠ” ê·œëª¨(2010~)
- ê¸°ì¡´ ë°ì´í„° ì²˜ë¦¬ ì´ìŠˆ ê³µìœ 
- ëŒ€ìš©ëŸ‰ ë°ì´í„° ë¶„ì‚°ì €ì¥/ì²˜ë¦¬ ë°©ë²• í•„ìš”

## Machine Learning

- ë°ì´í„°ì˜ ì†ì„±ì„ ì¼ë°˜ì ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” ë°©ë²•, ì£¼ë¡œ ë¶„ë¥˜/íšŒê·€ ì‘ì—…ì— ì‚¬ìš©ë¨(1950~)
- ì§€ë„í•™ìŠµ/ë¹„ì§€ë„í•™ìŠµ/êµ°ì§‘í™”
- ì²´ìŠ¤ ê²Œì„ìœ¼ë¡œë¶€í„° ë°œì „

## Deep learning

- ì‹¬ì¸µ ì¸ê³µì‹ ê²½ë§ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ëŠ” ê¸°ê³„í•™ìŠµ ë°©ë²•(2010~)
- ê¸°ì¡´ ê¸°ê³„í•™ìŠµ ë°©ë²•ì˜ ì„±ëŠ¥ì„ ë›°ì–´ ë„˜ìŒ

## Data Mining

- ë°ì´í„°ì— ë‚´ì¬ëœ ì†ì„±ì„ ë¶„ì„ (1930~)
- ê¸°ê³„í•™ìŠµê³¼ ìœ ì‚¬í•˜ë‚˜ ë°ì´í„° ê°„ì˜ ê·œì¹™ì„ ë¶„ì„í•˜ëŠ” ì¸¡ë©´ìœ¼ë¡œ ì°¨ë³„í™”

## Some history

- Frank Rosenblatt, Perceptron (1957, 1962): Early description and engineering of single-layer and multilayer artificial neural networks.

	![43](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/43.png)

- Kasparov vs Deep Blue, 1997

	![44](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/44.png)

- Lee Sedol vs AlphaGo, 2016

	![45](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/45.png)


### timelines

- 1943: Neural networks
- 1957-62: Perceptron
- 1970-86: Backpropagation, RBM, RNN
- 1979-98: CNN, MNIST, LSTM, Bidirectional RNN
- 2006: â€œDeep Learningâ€, DBNâ€¢ 2009: ImageNet + AlexNet
- 2014: GANs
- 2016-17: AlphaGo, AlphaZero
- Turing Award given for:
	- â€œThe conceptual and engineering breakthroughs that have made deep neural
	networks a critical component of computing.â€
	â€¢ Yann LeCun
	â€¢ Geoffrey Hinton
	â€¢ Yoshua Bengio

## Limitations of Deep Learning


![46](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/46.png)

- Prediction from Rodney Brooks:
â€œBy 2020, the popular press starts having stories that the era of Deep Learning is over.â€
- 2019 is the year it became cool to say that â€œdeep learningâ€ has limitations.
- Books, articles, lectures, debates, videos were released that learning-based methods cannot do commonsense reasoning.

## Statics of acceptance rate NeurIPS 


![47](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/47.png)


## Deep Learning Framework/Toolkits


![48](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/48.png)


## AlexNet


https://sushscience.wordpress.com/2016/12/04/understanding-alexnet/


![49](/assets/img/2023-05-24-9.-DNN-Deep-Neural-Network-(1).md/49.png)


---


[1] Geoffrey Hinton showed how to train deep network in 2006 


[2] Deep Neural Networks showed good classification performance with large image data set in 2012.


[[3] [Xavier Glorot, AISTATSâ€™11]](/a8916a1612b345718745d8cf339ab58b)


Deep Sparse Rectifier Neural Networks. _**Xavier Glorot,Â Antoine Bordes,Â Yoshua Bengio**_
Â _Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics._Â PMLR 15:315-323,Â 2011.

	- [https://proceedings.mlr.press/v15/glorot11a.html](https://proceedings.mlr.press/v15/glorot11a.html)

[[4] [Andrew L. Maas, ICMLâ€™13] ](/a8916a1612b345718745d8cf339ab58b)


Rectifier nonlinearities improve neural network acoustic models (2013) by Andrew L. Maas , Awni Y. Hannun , Andrew Y. Ng


[https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf](https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf)


[[5] [Kaiming He, arXivâ€™15] ](/a8916a1612b345718745d8cf339ab58b)


Deep Residual Learning for Image RecognitionğŸ“¹
by Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun


[https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385)


[[6] Dropout: A Simple Way to Prevent Neural Networks from Overfitting](/a8916a1612b345718745d8cf339ab58b)


_**Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov**_; 15(56):1929âˆ’1958, 2014.


[https://jmlr.org/papers/v15/srivastava14a.html](https://jmlr.org/papers/v15/srivastava14a.html)


[[7] Le-Net](/a8916a1612b345718745d8cf339ab58b)


[http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)


[8] [Ciresan 2010]


[9] ImageNet


ImageNet: A large-scale hierarchical image database


by Jia Deng; Wei Dong; Richard Socher; Li-Jia Li; Kai Li; Li Fei-Fei

